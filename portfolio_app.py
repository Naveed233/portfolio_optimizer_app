import streamlit as st
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import minimize
import logging
from datetime import datetime
import seaborn as sns
import tensorflow as tf
import random
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Set Streamlit page configuration
st.set_page_config(
    page_title="Portfolio Optimization App",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Define language options
languages = {
    'English': 'en',
    'æ—¥æœ¬èª': 'ja'
}

# Define language strings without emojis in plot and main titles
translations = {
    'en': {
        "title": "Portfolio Optimization with Advanced Features",
        "user_inputs": "ğŸ”§ User Inputs",
        "select_universe": "Select an Asset Universe:",
        "custom_tickers": "Enter stock tickers separated by commas (e.g., AAPL, MSFT, TSLA):",
        "add_portfolio": "Add to My Portfolio",
        "my_portfolio": "ğŸ“ My Portfolio",
        "no_assets": "No assets added yet.",
        "optimization_parameters": "ğŸ“… Optimization Parameters",
        "start_date": "Start Date",
        "end_date": "End Date",
        "risk_free_rate": "Enter the risk-free rate (in %):",
        "investment_strategy": "Choose your Investment Strategy:",
        "strategy_risk_free": "Risk-free Investment",
        "strategy_profit": "Profit-focused Investment",
        "target_return": "Select a specific target return (in %)",
        "train_lstm": "Train LSTM Model for Future Returns Prediction",
        "more_info_lstm": "â„¹ï¸ More Information on LSTM",
        "optimize_portfolio": "Optimize Portfolio",
        "optimize_sharpe": "Optimize for Highest Sharpe Ratio",
        "portfolio_analysis": "ğŸ” Portfolio Analysis & Optimization Results",
        "success_lstm": "ğŸ¤– LSTM model trained successfully!",
        "error_no_assets_lstm": "Please add at least one asset to your portfolio before training the LSTM model.",
        "error_no_assets_opt": "Please add at least one asset to your portfolio before optimization.",
        "error_date": "Start date must be earlier than end date.",
        "allocation_title": "ğŸ”‘ Optimal Portfolio Allocation (Target Return: {target}%)",
        "performance_metrics": "ğŸ“Š Portfolio Performance Metrics",
        "visual_analysis": "ğŸ“Š Visual Analysis",
        "portfolio_composition": "Portfolio Composition",
        "portfolio_metrics": "Portfolio Performance Metrics",
        "correlation_heatmap": "Asset Correlation Heatmap",
        "var": "Value at Risk (VaR)",
        "cvar": "Conditional Value at Risk (CVaR)",
        "max_drawdown": "Maximum Drawdown",
        "hhi": "Herfindahl-Hirschman Index (HHI)",
        "sharpe_ratio": "Sharpe Ratio",
        "sortino_ratio": "Sortino Ratio",
        "calmar_ratio": "Calmar Ratio",
        "beta": "Beta",
        "alpha": "Alpha",
        "explanation_var": "**Value at Risk (VaR):** Estimates the maximum potential loss of a portfolio over a specified time frame at a given confidence level.",
        "explanation_cvar": "**Conditional Value at Risk (CVaR):** Measures the expected loss exceeding the VaR, providing insights into tail risk.",
        "explanation_max_drawdown": "**Maximum Drawdown:** Measures the largest peak-to-trough decline in the portfolio value, indicating the worst-case scenario.",
        "explanation_hhi": "**Herfindahl-Hirschman Index (HHI):** A diversification metric that measures the concentration of investments in a portfolio.",
        "explanation_sharpe_ratio": "**Sharpe Ratio:** Measures risk-adjusted returns, indicating how much excess return you receive for the extra volatility endured.",
        "explanation_sortino_ratio": "**Sortino Ratio:** Similar to the Sharpe Ratio but only considers downside volatility, providing a more targeted risk-adjusted return measure.",
        "explanation_calmar_ratio": "**Calmar Ratio:** Compares the portfolio's annualized return to its maximum drawdown, indicating return per unit of risk.",
        "explanation_beta": "**Beta:** Measures the portfolio's volatility relative to a benchmark index (e.g., S&P 500). A beta greater than 1 indicates higher volatility than the benchmark.",
        "explanation_alpha": "**Alpha:** Represents the portfolio's excess return relative to the expected return based on its beta. Positive alpha indicates outperformance.",
        "explanation_lstm": "**Explanation of LSTM Model:**\nLong Short-Term Memory (LSTM) is a type of artificial neural network used in machine learning. It is particularly effective for predicting sequences and time series data, such as stock returns. LSTM models can remember information over long periods, making them suitable for capturing trends and patterns in historical financial data. However, while LSTM can provide valuable insights, it's important to note that predictions are not guarantees and should be used in conjunction with other analysis methods.",
        "feedback_sharpe_good": "Great! A Sharpe Ratio above 1 indicates that your portfolio is generating good returns for the level of risk taken.",
        "feedback_sharpe_average": "Average. A Sharpe Ratio between 0.5 and 1 suggests that your portfolio returns are acceptable for the risk taken.",
        "feedback_sharpe_poor": "Poor. A Sharpe Ratio below 0.5 indicates that your portfolio may not be generating adequate returns for the level of risk taken. Consider diversifying your assets or adjusting your investment strategy.",
        "success_optimize": "Portfolio optimization completed successfully!",
        "explanation_sharpe_button": "**Optimize for Highest Sharpe Ratio:**\nThe Sharpe Ratio measures the performance of your portfolio compared to a risk-free asset, after adjusting for its risk. Optimizing for the highest Sharpe Ratio aims to achieve the best possible return for the level of risk you are willing to take. This helps in constructing a portfolio that maximizes returns while minimizing unnecessary risk."
    },
    'ja': {
        "title": "é«˜åº¦ãªæ©Ÿèƒ½ã‚’å‚™ãˆãŸãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã‚¢ãƒ—ãƒª",
        "user_inputs": "ğŸ”§ ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›",
        "select_universe": "è³‡ç”£ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
        "custom_tickers": "æ ªå¼ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’ã‚«ãƒ³ãƒã§åŒºåˆ‡ã£ã¦å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šAAPL, MSFT, TSLAï¼‰ï¼š",
        "add_portfolio": "ãƒã‚¤ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«è¿½åŠ ",
        "my_portfolio": "ğŸ“ ãƒã‚¤ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª",
        "no_assets": "ã¾ã è³‡ç”£ãŒè¿½åŠ ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "optimization_parameters": "ğŸ“… æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
        "start_date": "é–‹å§‹æ—¥",
        "end_date": "çµ‚äº†æ—¥",
        "risk_free_rate": "ç„¡ãƒªã‚¹ã‚¯é‡‘åˆ©ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ%ï¼‰ï¼š",
        "investment_strategy": "æŠ•è³‡æˆ¦ç•¥ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
        "strategy_risk_free": "ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼æŠ•è³‡",
        "strategy_profit": "åˆ©ç›Šé‡è¦–æŠ•è³‡",
        "target_return": "ç‰¹å®šã®ç›®æ¨™ãƒªã‚¿ãƒ¼ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆ%ï¼‰",
        "train_lstm": "å°†æ¥ã®ãƒªã‚¿ãƒ¼ãƒ³äºˆæ¸¬ã®ãŸã‚ã«LSTMãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´",
        "more_info_lstm": "â„¹ï¸ LSTMã«é–¢ã™ã‚‹è©³ç´°æƒ…å ±",
        "optimize_portfolio": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’æœ€é©åŒ–",
        "optimize_sharpe": "ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§åŒ–ã®ãŸã‚ã«æœ€é©åŒ–",
        "portfolio_analysis": "ğŸ” ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æã¨æœ€é©åŒ–çµæœ",
        "success_lstm": "ğŸ¤– LSTMãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«è¨“ç·´ã•ã‚Œã¾ã—ãŸï¼",
        "error_no_assets_lstm": "LSTMãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹å‰ã«ã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«å°‘ãªãã¨ã‚‚1ã¤ã®è³‡ç”£ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚",
        "error_no_assets_opt": "æœ€é©åŒ–ã™ã‚‹å‰ã«ã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«å°‘ãªãã¨ã‚‚1ã¤ã®è³‡ç”£ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚",
        "error_date": "é–‹å§‹æ—¥ã¯çµ‚äº†æ—¥ã‚ˆã‚Šå‰ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚",
        "allocation_title": "ğŸ”‘ æœ€é©ãªãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªé…åˆ†ï¼ˆç›®æ¨™ãƒªã‚¿ãƒ¼ãƒ³ï¼š{target}%)",
        "performance_metrics": "ğŸ“Š ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™",
        "visual_analysis": "ğŸ“Š è¦–è¦šçš„åˆ†æ",
        "portfolio_composition": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹æˆ",
        "portfolio_metrics": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™",
        "correlation_heatmap": "è³‡ç”£ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
        "var": "ãƒªã‚¹ã‚¯ä¾¡å€¤ (VaR)",
        "cvar": "æ¡ä»¶ä»˜ããƒªã‚¹ã‚¯ä¾¡å€¤ (CVaR)",
        "max_drawdown": "æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³",
        "hhi": "ãƒãƒ¼ãƒ•ã‚£ãƒ³ãƒ€ãƒ¼ãƒ«ãƒ»ãƒãƒ¼ã‚·ãƒ¥ãƒãƒ³æŒ‡æ•° (HHI)",
        "sharpe_ratio": "ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª",
        "sortino_ratio": "ã‚½ãƒ«ãƒ†ã‚£ãƒ¼ãƒãƒ¬ã‚·ã‚ª",
        "calmar_ratio": "ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ª",
        "beta": "ãƒ™ãƒ¼ã‚¿",
        "alpha": "ã‚¢ãƒ«ãƒ•ã‚¡",
        "explanation_var": "**ãƒªã‚¹ã‚¯ä¾¡å€¤ (VaR):** æŒ‡å®šã•ã‚ŒãŸä¿¡é ¼æ°´æº–ã§ã€ç‰¹å®šã®æœŸé–“å†…ã«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãŒè¢«ã‚‹æœ€å¤§æå¤±ã‚’æ¨å®šã—ã¾ã™ã€‚",
        "explanation_cvar": "**æ¡ä»¶ä»˜ããƒªã‚¹ã‚¯ä¾¡å€¤ (CVaR):** VaRã‚’è¶…ãˆã‚‹æå¤±ã®æœŸå¾…å€¤ã‚’æ¸¬å®šã—ã€ãƒ†ãƒ¼ãƒ«ãƒªã‚¹ã‚¯ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚",
        "explanation_max_drawdown": "**æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³:** ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ä¾¡å€¤ãŒãƒ”ãƒ¼ã‚¯ã‹ã‚‰è°·ã«ä¸‹è½ã™ã‚‹æœ€å¤§å¹…ã‚’æ¸¬å®šã—ã€æœ€æ‚ªã®ã‚·ãƒŠãƒªã‚ªã‚’ç¤ºã—ã¾ã™ã€‚",
        "explanation_hhi": "**ãƒãƒ¼ãƒ•ã‚£ãƒ³ãƒ€ãƒ¼ãƒ«ãƒ»ãƒãƒ¼ã‚·ãƒ¥ãƒãƒ³æŒ‡æ•° (HHI):** ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå†…ã®æŠ•è³‡é›†ä¸­åº¦ã‚’æ¸¬å®šã™ã‚‹å¤šæ§˜åŒ–æŒ‡æ¨™ã§ã™ã€‚",
        "explanation_sharpe_ratio": "**ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª:** ãƒªã‚¹ã‚¯èª¿æ•´å¾Œã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ¸¬å®šã—ã€è¿½åŠ ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«å¯¾ã—ã¦ã©ã‚Œã ã‘ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’å—ã‘å–ã£ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚",
        "explanation_sortino_ratio": "**ã‚½ãƒ«ãƒ†ã‚£ãƒ¼ãƒãƒ¬ã‚·ã‚ª:** ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã¨ä¼¼ã¦ã„ã¾ã™ãŒã€ä¸‹æ–¹ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ã¿ã‚’è€ƒæ…®ã—ã€ã‚ˆã‚Šã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’çµã£ãŸãƒªã‚¹ã‚¯èª¿æ•´å¾Œã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚",
        "explanation_calmar_ratio": "**ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ª:** ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å¹´ç‡ãƒªã‚¿ãƒ¼ãƒ³ã‚’æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã¨æ¯”è¼ƒã—ã€ãƒªã‚¹ã‚¯å˜ä½ã‚ãŸã‚Šã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã—ã¾ã™ã€‚",
        "explanation_beta": "**ãƒ™ãƒ¼ã‚¿:** ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æŒ‡æ•°ï¼ˆä¾‹ï¼šS&P 500ï¼‰ã«å¯¾ã™ã‚‹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’æ¸¬å®šã—ã¾ã™ã€‚ãƒ™ãƒ¼ã‚¿ãŒ1ã‚’è¶…ãˆã‚‹ã¨ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚ˆã‚Šã‚‚é«˜ã„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ç¤ºã—ã¾ã™ã€‚",
        "explanation_alpha": "**ã‚¢ãƒ«ãƒ•ã‚¡:** ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ™ãƒ¼ã‚¿ã«åŸºã¥ãæœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã«å¯¾ã™ã‚‹è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’è¡¨ã—ã¾ã™ã€‚ãƒ—ãƒ©ã‚¹ã®ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã‚¢ã‚¦ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒ ã‚’ç¤ºã—ã¾ã™ã€‚",
        "explanation_lstm": "**LSTMãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜ï¼š**\né•·çŸ­æœŸè¨˜æ†¶ï¼ˆLSTMï¼‰ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã§ä½¿ç”¨ã•ã‚Œã‚‹äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸€ç¨®ã§ã™ã€‚ç‰¹ã«æ ªå¼ãƒªã‚¿ãƒ¼ãƒ³ã®ã‚ˆã†ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚„æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ã«åŠ¹æœçš„ã§ã™ã€‚LSTMãƒ¢ãƒ‡ãƒ«ã¯é•·æœŸé–“ã«ã‚ãŸã‚‹æƒ…å ±ã‚’ä¿æŒã§ãã‚‹ãŸã‚ã€éå»ã®é‡‘èãƒ‡ãƒ¼ã‚¿ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹ã®ã«é©ã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€LSTMã¯éå»ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ã„ã¦äºˆæ¸¬ã‚’è¡Œã†ãŸã‚ã€å¸‚å ´ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«ã‚ˆã£ã¦äºˆæ¸¬ãŒä¸ç¢ºå®Ÿã«ãªã‚‹ã“ã¨ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚ã—ãŸãŒã£ã¦ã€LSTMã®äºˆæ¸¬ã¯ä»–ã®åˆ†ææ‰‹æ³•ã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚",
        "feedback_sharpe_good": "ç´ æ™´ã‚‰ã—ã„ã§ã™ï¼ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªãŒ1ä»¥ä¸Šã§ã‚ã‚Œã°ã€ãƒªã‚¹ã‚¯ã«å¯¾ã—ã¦è‰¯å¥½ãªãƒªã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚",
        "feedback_sharpe_average": "å¹³å‡çš„ã§ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªãŒ0.5ã€œ1ã®é–“ã§ã‚ã‚Œã°ã€ãƒªã‚¹ã‚¯ã«å¯¾ã—ã¦è¨±å®¹ç¯„å›²å†…ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚",
        "feedback_sharpe_poor": "ä½ã„ã§ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªãŒ0.5æœªæº€ã§ã‚ã‚Œã°ã€ãƒªã‚¹ã‚¯ã«å¯¾ã—ã¦ååˆ†ãªãƒªã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚è³‡ç”£ã®å¤šæ§˜åŒ–ã‚„æŠ•è³‡æˆ¦ç•¥ã®èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
        "success_optimize": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æœ€é©åŒ–ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼",
        "explanation_sharpe_button": "**ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§åŒ–ã®ãŸã‚ã«æœ€é©åŒ–ï¼š**\nã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã¯ã€ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼è³‡ç”£ã¨æ¯”è¼ƒã—ã¦ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¸¬å®šã—ã€ãƒªã‚¹ã‚¯ã‚’èª¿æ•´ã—ãŸãƒªã‚¿ãƒ¼ãƒ³ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã§ã€ãƒªã‚¹ã‚¯ã«è¦‹åˆã£ãŸæœ€é«˜ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’é”æˆã™ã‚‹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒªã‚¹ã‚¯ã‚’æœ€å°é™ã«æŠ‘ãˆã¤ã¤ã€ãƒªã‚¿ãƒ¼ãƒ³ã‚’æœ€å¤§åŒ–ã™ã‚‹ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæŠ•è³‡æˆ¦ç•¥ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚"
    }
}

# Portfolio Optimizer Class
class PortfolioOptimizer:
    def __init__(self, tickers, start_date, end_date, risk_free_rate=0.02):
        """
        Initialize the PortfolioOptimizer with user-specified parameters.
        """
        self.tickers = tickers
        self.start_date = start_date
        self.end_date = end_date
        self.risk_free_rate = risk_free_rate
        self.returns = None
        self.benchmark_returns = None  # For Beta and Alpha

    def fetch_data(self):
        """
        Fetch historical price data and calculate daily returns.
        """
        logger.info(f"Fetching data for tickers: {self.tickers}")
        data = yf.download(
            self.tickers, start=self.start_date, end=self.end_date, progress=False
        )["Adj Close"]

        missing_tickers = set(self.tickers) - set(data.columns)
        if missing_tickers:
            st.warning(f"The following tickers were not fetched: {', '.join(missing_tickers)}")
            logger.warning(f"Missing tickers: {missing_tickers}")

        data.dropna(axis=1, inplace=True)

        if data.empty:
            logger.error("No data fetched after dropping missing tickers.")
            raise ValueError("No data fetched. Please check the tickers and date range.")

        # Update tickers to match the columns in the fetched data
        self.tickers = list(data.columns)
        self.returns = data.pct_change().dropna()
        logger.info(f"Fetched returns for {len(self.tickers)} tickers.")
        return self.tickers

    def fetch_benchmark_data(self, benchmark_ticker='^GSPC'):
        """
        Fetch benchmark data for Beta and Alpha calculations.
        """
        logger.info(f"Fetching benchmark data for ticker: {benchmark_ticker}")
        data = yf.download(
            benchmark_ticker, start=self.start_date, end=self.end_date, progress=False
        )["Adj Close"]

        if data.empty:
            logger.warning(f"No data fetched for benchmark ticker: {benchmark_ticker}")
            self.benchmark_returns = None
        else:
            self.benchmark_returns = data.pct_change().dropna()
            logger.info(f"Fetched benchmark returns for {benchmark_ticker}")

    def portfolio_stats(self, weights):
        """
        Calculate portfolio return, volatility, and Sharpe ratio.
        Ensure weights align with current tickers.
        """
        weights = np.array(weights)
        if len(weights) != len(self.tickers):
            raise ValueError("Weights array length does not match the number of tickers.")
        
        # Ensure weights sum to 1
        weights = weights / np.sum(weights)
        
        portfolio_return = np.dot(weights, self.returns.mean()) * 252
        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(self.returns.cov() * 252, weights)))
        sharpe_ratio = (portfolio_return - self.risk_free_rate) / portfolio_volatility
        return portfolio_return, portfolio_volatility, sharpe_ratio

    def sortino_ratio(self, weights, target=0):
        """
        Calculate Sortino Ratio for the portfolio.
        """
        weights = np.array(weights)
        portfolio_return = self.returns.dot(weights)
        downside_returns = portfolio_return[portfolio_return < target]
        expected_return = np.mean(portfolio_return) * 252
        downside_std = np.std(downside_returns) * np.sqrt(252)
        sortino = (expected_return - self.risk_free_rate) / downside_std if downside_std != 0 else np.nan
        return sortino

    def calmar_ratio(self, weights):
        """
        Calculate Calmar Ratio for the portfolio.
        """
        portfolio_return, _, _ = self.portfolio_stats(weights)
        max_dd = self.maximum_drawdown(weights)
        calmar = (portfolio_return) / abs(max_dd) if max_dd != 0 else np.nan
        return calmar

    def beta_alpha(self, weights, benchmark='^GSPC'):
        """
        Calculate Beta and Alpha for the portfolio relative to a benchmark.
        """
        if self.benchmark_returns is None:
            self.fetch_benchmark_data(benchmark)
        
        if self.benchmark_returns is None:
            return np.nan, np.nan  # Cannot calculate without benchmark data
        
        weights = np.array(weights)
        portfolio_return = self.returns.dot(weights)
        benchmark_return = self.benchmark_returns.reindex(portfolio_return.index).dropna()
        portfolio_return = portfolio_return.loc[benchmark_return.index]

        covariance = np.cov(portfolio_return, benchmark_return)[0][1]
        benchmark_variance = np.var(benchmark_return)
        beta = covariance / benchmark_variance if benchmark_variance != 0 else np.nan
        alpha = (portfolio_return.mean() * 252) - (self.risk_free_rate + beta * (benchmark_return.mean() * 252 - self.risk_free_rate))
        return beta, alpha

    def value_at_risk(self, weights, confidence_level=0.95):
        """
        Calculate Value at Risk (VaR) for the portfolio.
        """
        portfolio_returns = self.returns.dot(weights)
        var = np.percentile(portfolio_returns, (1 - confidence_level) * 100)
        return var

    def conditional_value_at_risk(self, weights, confidence_level=0.95):
        """
        Calculate Conditional Value at Risk (CVaR) for the portfolio.
        """
        portfolio_returns = self.returns.dot(weights)
        var = self.value_at_risk(weights, confidence_level)
        cvar = portfolio_returns[portfolio_returns <= var].mean()
        return cvar

    def maximum_drawdown(self, weights):
        """
        Calculate Maximum Drawdown for the portfolio.
        """
        portfolio_returns = self.returns.dot(weights)
        cumulative_returns = (1 + portfolio_returns).cumprod()
        peak = cumulative_returns.cummax()
        drawdown = (cumulative_returns - peak) / peak
        max_drawdown = drawdown.min()
        return max_drawdown

    def herfindahl_hirschman_index(self, weights):
        """
        Calculate Herfindahl-Hirschman Index (HHI) for the portfolio.
        """
        return np.sum(weights ** 2)

    def sharpe_ratio_objective(self, weights):
        """
        Objective function to maximize Sharpe Ratio.
        """
        _, _, sharpe = self.portfolio_stats(weights)
        return -sharpe  # Negative because we minimize

    def optimize_sharpe_ratio(self):
        """
        Optimize portfolio to maximize Sharpe Ratio.
        """
        num_assets = len(self.tickers)
        initial_weights = np.ones(num_assets) / num_assets
        bounds = tuple((0, 1) for _ in range(num_assets))
        constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}

        result = minimize(
            self.sharpe_ratio_objective, initial_weights,
            method='SLSQP', bounds=bounds, constraints=constraints
        )

        if result.success:
            logger.info("Optimized portfolio for Sharpe Ratio successfully.")
            return result.x
        else:
            logger.warning(f"Optimization failed: {result.message}")
            return initial_weights  # Fallback to equal weights

    def optimize_sortino_ratio(self):
        """
        Optimize portfolio to maximize Sortino Ratio.
        """
        def sortino_objective(weights):
            return -self.sortino_ratio(weights)
        
        num_assets = len(self.tickers)
        initial_weights = np.ones(num_assets) / num_assets
        bounds = tuple((0, 1) for _ in range(num_assets))
        constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}

        result = minimize(
            sortino_objective, initial_weights,
            method='SLSQP', bounds=bounds, constraints=constraints
        )

        if result.success:
            logger.info("Optimized portfolio for Sortino Ratio successfully.")
            return result.x
        else:
            logger.warning(f"Sortino optimization failed: {result.message}")
            return initial_weights  # Fallback to equal weights

    def calmar_ratio_objective(self, weights):
        """
        Objective function to maximize Calmar Ratio.
        """
        return -self.calmar_ratio(weights)

    def optimize_calmar_ratio(self):
        """
        Optimize portfolio to maximize Calmar Ratio.
        """
        num_assets = len(self.tickers)
        initial_weights = np.ones(num_assets) / num_assets
        bounds = tuple((0, 1) for _ in range(num_assets))
        constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}

        result = minimize(
            self.calmar_ratio_objective, initial_weights,
            method='SLSQP', bounds=bounds, constraints=constraints
        )

        if result.success:
            logger.info("Optimized portfolio for Calmar Ratio successfully.")
            return result.x
        else:
            logger.warning(f"Calmar optimization failed: {result.message}")
            return initial_weights  # Fallback to equal weights

    def beta_alpha_objective(self, weights, target_alpha=0.0):
        """
        Objective function to maximize Alpha while controlling Beta.
        """
        beta, alpha = self.beta_alpha(weights)
        return -alpha  # Negative because we minimize

    def optimize_alpha(self, target_beta=1.0):
        """
        Optimize portfolio to maximize Alpha with a target Beta.
        """
        def objective(weights):
            beta, alpha = self.beta_alpha(weights)
            return -alpha  # Negative because we minimize

        num_assets = len(self.tickers)
        initial_weights = np.ones(num_assets) / num_assets
        bounds = tuple((0, 1) for _ in range(num_assets))
        constraints = [
            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},
            {'type': 'eq', 'fun': lambda x: self.beta_alpha(x)[0] - target_beta}
        ]

        result = minimize(
            objective, initial_weights,
            method='SLSQP', bounds=bounds, constraints=constraints
        )

        if result.success:
            logger.info("Optimized portfolio for Alpha successfully.")
            return result.x
        else:
            logger.warning(f"Alpha optimization failed: {result.message}")
            return initial_weights  # Fallback to equal weights

    def prepare_data_for_lstm(self):
        """
        Prepare data for LSTM model.
        """
        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(self.returns.values)
        
        X, y = [], []
        look_back = 60  # Look-back period (e.g., 60 days)
        for i in range(look_back, len(scaled_data)):
            X.append(scaled_data[i-look_back:i])
            y.append(scaled_data[i])
        
        # Split into training and testing sets (e.g., 80% train, 20% test)
        split = int(len(X) * 0.8)
        X_train, X_test = X[:split], X[split:]
        y_train, y_test = y[:split], y[split:]
    
        if not X_train or not y_train:
            raise ValueError("Not enough data to create training samples. Please adjust the date range or add more data.")
    
        X_train, y_train = np.array(X_train), np.array(y_train)
        X_test, y_test = np.array(X_test), np.array(y_test)
        return X_train, y_train, X_test, y_test, scaler

    def train_lstm_model(self, X_train, y_train, epochs=10, batch_size=32):
        # Set random seed for reproducibility
        seed_value = 42
        np.random.seed(seed_value)
        tf.random.set_seed(seed_value)
        random.seed(seed_value)
        """
        Train LSTM model.
        """
        model = tf.keras.Sequential()
        model.add(tf.keras.layers.LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
        model.add(tf.keras.layers.LSTM(units=50))
        model.add(tf.keras.layers.Dense(units=X_train.shape[2]))
        model.compile(optimizer='adam', loss='mean_squared_error')
        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)
        return model

    def predict_future_returns(self, model, scaler, steps=30):
        """
        Predict future returns using the LSTM model.
        """
        if len(self.returns) < 60:
            raise ValueError("Not enough data to make predictions. Ensure there are at least 60 days of returns data.")

        last_data = self.returns[-60:].values
        scaled_last_data = scaler.transform(last_data)

        X_test = []
        X_test.append(scaled_last_data)
        X_test = np.array(X_test)
        
        predicted_scaled = model.predict(X_test)
        predicted = scaler.inverse_transform(predicted_scaled)
        
        # Ensure the length matches the number of future steps requested
        future_returns = predicted[0][:steps] if len(predicted[0]) >= steps else predicted[0]
        return future_returns

    def evaluate_model(self, model, scaler, X_test, y_test):
        """
        Evaluate the LSTM model using MAE, RMSE, and R-squared metrics.
        """
        predictions_scaled = model.predict(X_test)
        predictions = scaler.inverse_transform(predictions_scaled)
        y_test_inverse = scaler.inverse_transform(y_test)

        # Calculate evaluation metrics
        mae = mean_absolute_error(y_test_inverse, predictions)
        rmse = np.sqrt(mean_squared_error(y_test_inverse, predictions))
        r2 = r2_score(y_test_inverse, predictions)

        return mae, rmse, r2

    def compute_efficient_frontier(self, num_portfolios=10000):
        """
        Compute the Efficient Frontier by generating random portfolios.
        """
        results = np.zeros((5, num_portfolios))  # Added Sortino and Calmar
        weights_record = []
        for i in range(num_portfolios):
            weights = np.random.dirichlet(np.ones(len(self.tickers)), size=1)[0]
            weights_record.append(weights)
            portfolio_return, portfolio_volatility, sharpe = self.portfolio_stats(weights)
            sortino = self.sortino_ratio(weights)
            calmar = self.calmar_ratio(weights)
            hhi = self.herfindahl_hirschman_index(weights)
            results[0,i] = portfolio_volatility
            results[1,i] = portfolio_return
            results[2,i] = sharpe
            results[3,i] = sortino
            results[4,i] = calmar
        return results, weights_record

# Helper Functions
def extract_ticker(asset_string):
    """
    Extract ticker symbol from asset string.
    """
    return asset_string.split(' - ')[0].strip() if ' - ' in asset_string else asset_string.strip()

def get_translated_text(lang, key):
    """
    Retrieve translated text based on selected language.
    """
    return translations.get(lang, translations['en']).get(key, key)

def analyze_var(var):
    """
    Analyze Value at Risk (VaR).
    """
    if var < -0.05:
        return "High Risk: Your portfolio has a significant potential loss."
    elif -0.05 <= var < -0.02:
        return "Moderate Risk: Your portfolio has a moderate potential loss."
    else:
        return "Low Risk: Your portfolio is relatively safe."

def analyze_cvar(cvar):
    """
    Analyze Conditional Value at Risk (CVaR).
    """
    if cvar < -0.07:
        return "High Tail Risk: Significant losses beyond VaR."
    elif -0.07 <= cvar < -0.04:
        return "Moderate Tail Risk: Moderate losses beyond VaR."
    else:
        return "Low Tail Risk: Minimal losses beyond VaR."

def analyze_max_drawdown(dd):
    """
    Analyze Maximum Drawdown.
    """
    if dd < -0.20:
        return "Severe Drawdown: The portfolio has experienced a major decline."
    elif -0.20 <= dd < -0.10:
        return "Moderate Drawdown: The portfolio has experienced a noticeable decline."
    else:
        return "Minor Drawdown: The portfolio has maintained stability."

def analyze_hhi(hhi):
    """
    Analyze Herfindahl-Hirschman Index (HHI).
    """
    if hhi > 0.6:
        return "High Concentration: Portfolio lacks diversification."
    elif 0.3 < hhi <= 0.6:
        return "Moderate Concentration: Portfolio has some diversification."
    else:
        return "Good Diversification: Portfolio is well-diversified."

def analyze_sharpe(sharpe):
    """
    Analyze Sharpe Ratio.
    """
    if sharpe > 2:
        return "Excellent Sharpe Ratio: High risk-adjusted returns."
    elif 1 < sharpe <= 2:
        return "Good Sharpe Ratio: Solid risk-adjusted returns."
    elif 0.5 < sharpe <= 1:
        return "Average Sharpe Ratio: Acceptable risk-adjusted returns."
    else:
        return "Poor Sharpe Ratio: Consider improving risk-adjusted returns."

def analyze_sortino(sortino):
    """
    Analyze Sortino Ratio.
    """
    if sortino > 2:
        return "Excellent Sortino Ratio: High risk-adjusted returns considering downside risk."
    elif 1 < sortino <= 2:
        return "Good Sortino Ratio: Solid risk-adjusted returns considering downside risk."
    elif 0.5 < sortino <= 1:
        return "Average Sortino Ratio: Acceptable risk-adjusted returns considering downside risk."
    else:
        return "Poor Sortino Ratio: Consider improving downside risk management."

def analyze_calmar(calmar):
    """
    Analyze Calmar Ratio.
    """
    if calmar > 0.5:
        return "Excellent Calmar Ratio: High return per unit of drawdown risk."
    elif 0.3 < calmar <= 0.5:
        return "Good Calmar Ratio: Solid return per unit of drawdown risk."
    elif 0.1 < calmar <= 0.3:
        return "Average Calmar Ratio: Acceptable return per unit of drawdown risk."
    else:
        return "Poor Calmar Ratio: Consider strategies to improve return or reduce drawdown."

def analyze_beta(beta):
    """
    Analyze Beta.
    """
    if beta > 1.2:
        return "High Beta: Portfolio is significantly more volatile than the benchmark."
    elif 0.8 < beta <= 1.2:
        return "Moderate Beta: Portfolio volatility is comparable to the benchmark."
    else:
        return "Low Beta: Portfolio is less volatile than the benchmark."

def analyze_alpha(alpha):
    """
    Analyze Alpha.
    """
    if alpha > 0.05:
        return "Positive Alpha: Portfolio is outperforming the benchmark."
    elif -0.05 <= alpha <= 0.05:
        return "Neutral Alpha: Portfolio is performing in line with the benchmark."
    else:
        return "Negative Alpha: Portfolio is underperforming the benchmark."

def display_metrics(metrics, lang):
    """
    Display metrics with larger font, analysis in smaller text, and spacing.
    """
    metric_keys = [
        "var", "cvar", "max_drawdown", "hhi", "sharpe_ratio",
        "sortino_ratio", "calmar_ratio", "beta", "alpha"
    ]
    analysis_functions = {
        "var": analyze_var,
        "cvar": analyze_cvar,
        "max_drawdown": analyze_max_drawdown,
        "hhi": analyze_hhi,
        "sharpe_ratio": analyze_sharpe,
        "sortino_ratio": analyze_sortino,
        "calmar_ratio": analyze_calmar,
        "beta": analyze_beta,
        "alpha": analyze_alpha
    }

    for key in metric_keys:
        display_key = get_translated_text(lang, key)
        value = metrics.get(key, None)
        if value is not None:
            if key in ["hhi"]:
                display_value = f"{value:.4f}"
            elif key in ["beta"]:
                display_value = f"{value:.2f}"
            elif key in ["alpha"]:
                display_value = f"{value:.4f}"
            elif key in ["sharpe_ratio", "sortino_ratio", "calmar_ratio"]:
                display_value = f"{value:.2f}"
            else:
                display_value = f"{value:.2%}"
            # Metric with larger font
            st.markdown(f"<h3>{display_key}: {display_value}</h3>", unsafe_allow_html=True)
            # Explanation
            explanation_key = f"explanation_{key}"
            explanation = translations[lang].get(explanation_key, "")
            st.markdown(explanation)
            # Provide feedback based on the metric
            feedback = analysis_functions[key](value)
            if feedback:
                # Analysis in smaller font
                st.markdown(f"<p style='font-size:12px;'><strong>Analysis:</strong> {feedback}</p>", unsafe_allow_html=True)
            # Add spacing
            st.markdown("<br>", unsafe_allow_html=True)

# Streamlit App
def main():
    # Language Selection
    st.sidebar.header("ğŸŒ Language Selection")
    selected_language = st.sidebar.selectbox("Select Language:", options=list(languages.keys()), index=0)
    lang = languages[selected_language]

    # Title
    st.title(get_translated_text(lang, "title"))

    # Sidebar for User Inputs
    st.sidebar.header(get_translated_text(lang, "user_inputs"))

    # Define preset universes
    universe_options = {
        'Tech Giants': ['AAPL - Apple', 'MSFT - Microsoft', 'GOOGL - Alphabet', 'AMZN - Amazon', 'META - Meta Platforms', 'TSLA - Tesla', 'NVDA - NVIDIA', 'ADBE - Adobe', 'INTC - Intel', 'CSCO - Cisco'],
        'Finance Leaders': ['JPM - JPMorgan Chase', 'BAC - Bank of America', 'WFC - Wells Fargo', 'C - Citigroup', 'GS - Goldman Sachs', 'MS - Morgan Stanley', 'AXP - American Express', 'BLK - BlackRock', 'SCHW - Charles Schwab', 'USB - U.S. Bancorp'],
        'Healthcare Majors': ['JNJ - Johnson & Johnson', 'PFE - Pfizer', 'UNH - UnitedHealth', 'MRK - Merck', 'ABBV - AbbVie', 'ABT - Abbott', 'TMO - Thermo Fisher Scientific', 'MDT - Medtronic', 'DHR - Danaher', 'BMY - Bristol-Myers Squibb'],
        'Custom': []
    }

    universe_choice = st.sidebar.selectbox(get_translated_text(lang, "select_universe"), options=list(universe_options.keys()), index=0)

    if universe_choice == 'Custom':
        custom_tickers = st.sidebar.text_input(
            get_translated_text(lang, "custom_tickers"),
            value=""
        )
    else:
        selected_universe_assets = st.sidebar.multiselect(
            get_translated_text(lang, "add_portfolio"),
            universe_options[universe_choice],
            default=[]  # No default selection to prevent auto-adding
        )

    # Initialize Session State for Portfolio
    if 'my_portfolio' not in st.session_state:
        st.session_state['my_portfolio'] = []

    # Add Selected Universe Assets to Portfolio
    if universe_choice != 'Custom':
        if selected_universe_assets:
            if st.sidebar.button(get_translated_text(lang, "add_portfolio")):
                new_tickers = [extract_ticker(asset) for asset in selected_universe_assets]
                # Add only unique tickers
                st.session_state['my_portfolio'] = list(set(st.session_state['my_portfolio'] + new_tickers))
                st.sidebar.success(get_translated_text(lang, "add_portfolio") + " " + get_translated_text(lang, "my_portfolio"))
    else:
        # Add Custom Tickers to Portfolio
        if custom_tickers:
            if st.sidebar.button(get_translated_text(lang, "add_portfolio")):
                new_tickers = [ticker.strip().upper() for ticker in custom_tickers.split(",") if ticker.strip()]
                # Add only unique tickers
                st.session_state['my_portfolio'] = list(set(st.session_state['my_portfolio'] + new_tickers))
                st.sidebar.success(get_translated_text(lang, "add_portfolio") + " " + get_translated_text(lang, "my_portfolio"))

    # Display 'My Portfolio' in Sidebar
    st.sidebar.subheader(get_translated_text(lang, "my_portfolio"))
    if st.session_state['my_portfolio']:
        st.sidebar.write(", ".join(st.session_state['my_portfolio']))
    else:
        st.sidebar.write(get_translated_text(lang, "no_assets"))

    # Portfolio Optimization Parameters in Sidebar
    st.sidebar.header(get_translated_text(lang, "optimization_parameters"))

    # Date Inputs
    start_date = st.sidebar.date_input(get_translated_text(lang, "start_date"), value=datetime(2024, 1, 1), max_value=datetime.today())
    end_date = st.sidebar.date_input(get_translated_text(lang, "end_date"), value=datetime.today(), max_value=datetime.today())

    # Risk-Free Rate Input
    risk_free_rate = st.sidebar.number_input(get_translated_text(lang, "risk_free_rate"), value=2.0, step=0.1) / 100

    # Investment Strategy Options
    investment_strategy = st.sidebar.radio(
        get_translated_text(lang, "investment_strategy"),
        (get_translated_text(lang, "strategy_risk_free"), get_translated_text(lang, "strategy_profit"))
    )

    # Display Target Return Slider only if "Risk-free Investment" is selected
    if investment_strategy == get_translated_text(lang, "strategy_risk_free"):
        specific_target_return = st.sidebar.slider(
            get_translated_text(lang, "target_return"), 
            min_value=-5.0, max_value=20.0, value=5.0, step=0.1
        ) / 100
    else:
        specific_target_return = None  # Not used in Profit-focused Investment

    # Train LSTM Button
    train_lstm = st.sidebar.button(get_translated_text(lang, "train_lstm"))

    # Optimize Portfolio Button
    optimize_portfolio = st.sidebar.button(get_translated_text(lang, "optimize_portfolio"))

    # Optimize for Highest Sharpe Ratio Button
    optimize_sharpe = st.sidebar.button(get_translated_text(lang, "optimize_sharpe"))

    # Main Area for Outputs
    st.header(get_translated_text(lang, "portfolio_analysis"))

    # Train LSTM Model Section
    if train_lstm:
        if not st.session_state['my_portfolio']:
            st.error(get_translated_text(lang, "error_no_assets_lstm"))
        else:
            try:
                clean_tickers = [ticker for ticker in st.session_state['my_portfolio']]
                optimizer = PortfolioOptimizer(clean_tickers, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), risk_free_rate)
                optimizer.fetch_data()

                # Prepare data for LSTM
                X_train, y_train, X_test, y_test, scaler = optimizer.prepare_data_for_lstm()
                model = optimizer.train_lstm_model(X_train, y_train, epochs=10, batch_size=32)
                mae, rmse, r2 = optimizer.evaluate_model(model, scaler, X_test, y_test)

                st.success(get_translated_text(lang, "success_lstm"))

                # Display Evaluation Metrics
                st.subheader("LSTM Model Evaluation Metrics")
                eval_metrics = {
                    "Mean Absolute Error (MAE)": mae,
                    "Root Mean Squared Error (RMSE)": rmse,
                    "R-squared (RÂ²)": r2
                }
                eval_df = pd.DataFrame.from_dict(eval_metrics, orient='index', columns=['Value'])
                st.table(eval_df.style.format({"Value": "{:.4f}"}))

                # Predict future returns for the next 30 days
                future_returns = optimizer.predict_future_returns(model, scaler, steps=30)
                future_dates = pd.date_range(end_date, periods=len(future_returns), freq='B').to_pydatetime().tolist()  # 'B' for business days

                # Create a DataFrame for plotting
                prediction_df = pd.DataFrame({
                    'Date': future_dates,
                    'Predicted Returns': future_returns
                })

                # Plot future predictions
                fig, ax = plt.subplots(figsize=(10, 4))
                ax.plot(prediction_df['Date'], prediction_df['Predicted Returns'], label="Predicted Returns", color='blue')
                ax.set_xlabel("Date")
                ax.set_ylabel("Predicted Returns")
                ax.set_title(get_translated_text(lang, "train_lstm"))
                ax.legend()
                plt.xticks(rotation=45)
                plt.tight_layout()
                st.pyplot(fig)

                # Add LSTM Explanation using Expander
                with st.expander(get_translated_text(lang, "more_info_lstm")):
                    explanation = get_translated_text(lang, "explanation_lstm")
                    st.markdown(explanation)

            except ValueError as ve:
                st.error(str(ve))
            except Exception as e:
                logger.exception("An error occurred during LSTM training or prediction.")
                st.error(f"{e}")

    # Function to Display Optimization Results
    def display_optimization_results(optimizer, optimal_weights, lang, target_return=None, strategy="Sharpe Ratio"):
        portfolio_return, portfolio_volatility, sharpe_ratio = optimizer.portfolio_stats(optimal_weights)
        sortino_ratio = optimizer.sortino_ratio(optimal_weights)
        calmar_ratio = optimizer.calmar_ratio(optimal_weights)
        beta, alpha = optimizer.beta_alpha(optimal_weights)
        var_95 = optimizer.value_at_risk(optimal_weights, confidence_level=0.95)
        cvar_95 = optimizer.conditional_value_at_risk(optimal_weights, confidence_level=0.95)
        max_dd = optimizer.maximum_drawdown(optimal_weights)
        hhi = optimizer.herfindahl_hirschman_index(optimal_weights)

        allocation = pd.DataFrame({
            "Asset": optimizer.tickers,
            "Weight (%)": np.round(optimal_weights * 100, 2)
        })
        allocation = allocation[allocation['Weight (%)'] > 0].reset_index(drop=True)

        # Display Allocation
        if strategy == "Sharpe Ratio":
            allocation_title = get_translated_text(lang, "allocation_title").format(target=round(target_return*100, 2) if target_return else "N/A")
            st.markdown(f"<h3>{allocation_title}</h3>", unsafe_allow_html=True)
        else:
            st.markdown(f"<h3>ğŸ”‘ Optimal Portfolio Allocation ({strategy})</h3>", unsafe_allow_html=True)
        st.dataframe(allocation.style.format({"Weight (%)": "{:.2f}"}))

        # Display Performance Metrics
        st.markdown(f"<h3>{get_translated_text(lang, 'performance_metrics')}</h3>", unsafe_allow_html=True)
        metrics = {
            "var": var_95,
            "cvar": cvar_95,
            "max_drawdown": max_dd,
            "hhi": hhi,
            "sharpe_ratio": sharpe_ratio,
            "sortino_ratio": sortino_ratio,
            "calmar_ratio": calmar_ratio,
            "beta": beta,
            "alpha": alpha
        }

        display_metrics(metrics, lang)

        # Display Visuals
        st.markdown(f"<h3>{get_translated_text(lang, 'visual_analysis')}</h3>", unsafe_allow_html=True)
        col1, col2 = st.columns(2)

        with col1:
            # Pie Chart for Allocation
            fig1, ax1 = plt.subplots(figsize=(5, 4))
            ax1.pie(allocation['Weight (%)'], labels=allocation['Asset'], autopct='%1.1f%%', startangle=90, textprops={'fontsize': 10})
            ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
            ax1.set_title(get_translated_text(lang, "portfolio_composition"))
            st.pyplot(fig1)

        with col2:
            # Bar Chart for Performance Metrics
            fig2, ax2 = plt.subplots(figsize=(5, 4))
            performance_metrics = {
                "Expected Annual Return (%)": portfolio_return * 100,
                "Annual Volatility\n(Risk) (%)": portfolio_volatility * 100,
                "Sharpe Ratio": sharpe_ratio,
                "Sortino Ratio": sortino_ratio,
                "Calmar Ratio": calmar_ratio
            }
            metrics_bar = pd.DataFrame.from_dict(performance_metrics, orient='index', columns=['Value'])
            sns.barplot(x=metrics_bar.index, y='Value', data=metrics_bar, palette='viridis', ax=ax2)
            ax2.set_title(get_translated_text(lang, "portfolio_metrics"))
            for p in ax2.patches:
                ax2.annotate(f"{p.get_height():.2f}", (p.get_x() + p.get_width() / 2., p.get_height()),
                             ha='center', va='bottom', fontsize=10)
            plt.xticks(rotation=0, ha='center')  # Adjust rotation if needed
            plt.tight_layout()
            st.pyplot(fig2)

        # Correlation Heatmap
        st.markdown(f"<h3>{get_translated_text(lang, 'correlation_heatmap')}</h3>", unsafe_allow_html=True)
        correlation_matrix = optimizer.returns.corr()
        fig3, ax3 = plt.subplots(figsize=(8, 6))
        sns.heatmap(correlation_matrix, annot=True, cmap='Spectral', linewidths=0.3, ax=ax3, cbar_kws={'shrink': 0.8}, annot_kws={'fontsize': 8})
        plt.title(get_translated_text(lang, "correlation_heatmap"))
        plt.tight_layout()
        st.pyplot(fig3)

        # Additional Visual: Cumulative Returns
        st.markdown(f"<h3>Cumulative Returns</h3>", unsafe_allow_html=True)
        cumulative_returns = (1 + optimizer.returns.dot(optimal_weights)).cumprod()
        fig4, ax4 = plt.subplots(figsize=(10, 4))
        ax4.plot(cumulative_returns.index, cumulative_returns.values, label="Portfolio Cumulative Returns", color='green')
        ax4.set_xlabel("Date")
        ax4.set_ylabel("Cumulative Returns")
        ax4.set_title("Cumulative Returns Over Time")
        ax4.legend()
        plt.xticks(rotation=45)
        plt.tight_layout()
        st.pyplot(fig4)

    # Optimize Portfolio Section
    if optimize_portfolio:
        if not st.session_state['my_portfolio']:
            st.error(get_translated_text(lang, "error_no_assets_opt"))
        elif start_date >= end_date:
            st.error(get_translated_text(lang, "error_date"))
        else:
            try:
                clean_tickers = [ticker for ticker in st.session_state['my_portfolio']]
                optimizer = PortfolioOptimizer(clean_tickers, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), risk_free_rate)
                # Fetch data and update tickers in case some are dropped
                updated_tickers = optimizer.fetch_data()

                if investment_strategy == get_translated_text(lang, "strategy_risk_free"):
                    # Optimize for minimum volatility
                    if specific_target_return is None:
                        st.error("Please select a target return for Risk-free Investment strategy.")
                        st.stop()
                    optimal_weights = optimizer.min_volatility(specific_target_return)
                    details = "Details: You selected a 'Risk-free Investment' strategy, aiming for minimal risk exposure while attempting to achieve the specified target return."
                else:
                    # Optimize for Sharpe Ratio
                    optimal_weights = optimizer.optimize_sharpe_ratio()
                    details = "Details: You selected a 'Profit-focused Investment' strategy, aiming for maximum potential returns with an acceptance of higher risk."

                st.markdown(f"<p><strong>{details}</strong></p>", unsafe_allow_html=True)

                display_optimization_results(optimizer, optimal_weights, lang, specific_target_return, strategy="Sharpe Ratio")

                st.success(get_translated_text(lang, "success_optimize"))

            except ValueError as ve:
                st.error(str(ve))
            except Exception as e:
                logger.exception("An unexpected error occurred during optimization.")
                st.error(f"{e}")

    # Optimize for Highest Sharpe Ratio Section
    if optimize_sharpe:
        if not st.session_state['my_portfolio']:
            st.error(get_translated_text(lang, "error_no_assets_opt"))
        elif start_date >= end_date:
            st.error(get_translated_text(lang, "error_date"))
        else:
            try:
                clean_tickers = [ticker for ticker in st.session_state['my_portfolio']]
                optimizer = PortfolioOptimizer(clean_tickers, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), risk_free_rate)
                # Fetch data and update tickers in case some are dropped
                updated_tickers = optimizer.fetch_data()

                # Optimize for Highest Sharpe Ratio
                optimal_weights = optimizer.optimize_sharpe_ratio()
                display_optimization_results(optimizer, optimal_weights, lang, strategy="Sharpe Ratio")

                st.success(get_translated_text(lang, "success_optimize"))

                # Provide explanation
                st.markdown(get_translated_text(lang, "explanation_sharpe_button"))

            except ValueError as ve:
                st.error(str(ve))
            except Exception as e:
                logger.exception("An unexpected error occurred during Sharpe Ratio optimization.")
                st.error(f"{e}")

if __name__ == "__main__":
    main()
