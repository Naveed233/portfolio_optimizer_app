import streamlit as st
import yfinance as yf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import minimize
import logging
from datetime import datetime
import seaborn as sns
import tensorflow as tf
import random
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Set Streamlit page configuration
st.set_page_config(
    page_title="Portfolio Optimization App",
    layout="wide",
    initial_sidebar_state="expanded",
)

# Define language options
languages = {
    'English': 'en',
    'æ—¥æœ¬èª': 'ja'
}

# Define language strings without emojis in plot and main titles
translations = {
    'en': {
        "title": "Portfolio Optimization with Advanced Features",
        "user_inputs": "ğŸ”§ User Inputs",
        "select_universe": "Select an Asset Universe:",
        "custom_tickers": "Enter stock tickers separated by commas (e.g., AAPL, MSFT, TSLA):",
        "add_portfolio": "Add to My Portfolio",
        "my_portfolio": "ğŸ“ My Portfolio",
        "no_assets": "No assets added yet.",
        "optimization_parameters": "ğŸ“… Optimization Parameters",
        "start_date": "Start Date",
        "end_date": "End Date",
        "risk_free_rate": "Enter the risk-free rate (in %):",
        "investment_strategy": "Choose your Investment Strategy:",
        "strategy_risk_free": "Risk-free Investment",
        "strategy_profit": "Profit-focused Investment",
        "target_return": "Select a specific target return (in %)",
        "train_lstm": "Train LSTM Model for Future Returns Prediction",
        "more_info_lstm": "â„¹ï¸ More Information on LSTM",
        "optimize_portfolio": "Optimize Portfolio",
        "optimize_sharpe": "Optimize for Highest Sharpe Ratio",
        "compare_portfolios": "Compare Sharpe vs Base",
        "portfolio_analysis": "ğŸ” Portfolio Analysis & Optimization Results",
        "success_lstm": "ğŸ¤– LSTM model trained successfully!",
        "error_no_assets_lstm": "Please add at least one asset to your portfolio before training the LSTM model.",
        "error_no_assets_opt": "Please add at least one asset to your portfolio before optimization.",
        "error_date": "Start date must be earlier than end date.",
        "allocation_title": "ğŸ”‘ Optimal Portfolio Allocation (Target Return: {target}%)",
        "performance_metrics": "ğŸ“Š Portfolio Performance Metrics",
        "visual_analysis": "ğŸ“Š Visual Analysis",
        "portfolio_composition": "Portfolio Composition",
        "portfolio_metrics": "Portfolio Performance Metrics",
        "correlation_heatmap": "Asset Correlation Heatmap",
        "var": "Value at Risk (VaR)",
        "cvar": "Conditional Value at Risk (CVaR)",
        "max_drawdown": "Maximum Drawdown",
        "hhi": "Herfindahl-Hirschman Index (HHI)",
        "sharpe_ratio": "Sharpe Ratio",
        "sortino_ratio": "Sortino Ratio",
        "calmar_ratio": "Calmar Ratio",
        "beta": "Beta",
        "alpha": "Alpha",
        "explanation_var": "**Value at Risk (VaR):** Estimates the maximum potential loss of a portfolio over a specified time frame at a given confidence level.",
        "explanation_cvar": "**Conditional Value at Risk (CVaR):** Measures the expected loss exceeding the VaR, providing insights into tail risk.",
        "explanation_max_drawdown": "**Maximum Drawdown:** Measures the largest peak-to-trough decline in the portfolio value, indicating the worst-case scenario.",
        "explanation_hhi": "**Herfindahl-Hirschman Index (HHI):** A diversification metric that measures the concentration of investments in a portfolio.",
        "explanation_sharpe_ratio": "**Sharpe Ratio:** Measures risk-adjusted returns, indicating how much excess return you receive for the extra volatility endured.",
        "explanation_sortino_ratio": "**Sortino Ratio:** Similar to the Sharpe Ratio but only considers downside volatility, providing a more targeted risk-adjusted return measure.",
        "explanation_calmar_ratio": "**Calmar Ratio:** Compares the portfolio's annualized return to its maximum drawdown, indicating return per unit of risk.",
        "explanation_beta": "**Beta:** Measures the portfolio's volatility relative to a benchmark index (e.g., S&P 500). A beta greater than 1 indicates higher volatility than the benchmark.",
        "explanation_alpha": "**Alpha:** Represents the portfolio's excess return relative to the expected return based on its beta. Positive alpha indicates outperformance.",
        "explanation_lstm": "**Explanation of LSTM Model:**\nLong Short-Term Memory (LSTM) is a type of artificial neural network used in machine learning. It is particularly effective for predicting sequences and time series data, such as stock returns. LSTM models can remember information over long periods, making them suitable for capturing trends and patterns in historical financial data. However, while LSTM can provide valuable insights, it's important to note that predictions are not guarantees and should be used in conjunction with other analysis methods.",
        "feedback_sharpe_good": "Great! A Sharpe Ratio above 1 indicates that your portfolio is generating good returns for the level of risk taken.",
        "feedback_sharpe_average": "Average. A Sharpe Ratio between 0.5 and 1 suggests that your portfolio returns are acceptable for the risk taken.",
        "feedback_sharpe_poor": "Poor. A Sharpe Ratio below 0.5 indicates that your portfolio may not be generating adequate returns for the level of risk taken. Consider diversifying your assets or adjusting your investment strategy.",
        "feedback_sortino_good": "Excellent Sortino Ratio! Your portfolio is generating high returns relative to downside risk.",
        "feedback_sortino_average": "Average Sortino Ratio. Your portfolio returns are acceptable considering downside volatility.",
        "feedback_sortino_poor": "Poor Sortino Ratio. Consider strategies to reduce downside risk or improve returns.",
        "feedback_calmar_good": "Excellent Calmar Ratio! High return per unit of drawdown risk.",
        "feedback_calmar_average": "Good Calmar Ratio. Solid return relative to drawdown risk.",
        "feedback_calmar_poor": "Poor Calmar Ratio. Consider strategies to improve return or reduce drawdown.",
        "feedback_beta_high": "High Beta: Your portfolio is significantly more volatile than the benchmark.",
        "feedback_beta_moderate": "Moderate Beta: Portfolio volatility is comparable to the benchmark.",
        "feedback_beta_low": "Low Beta: Your portfolio is less volatile than the benchmark.",
        "feedback_alpha_positive": "Positive Alpha: Portfolio is outperforming the benchmark.",
        "feedback_alpha_neutral": "Neutral Alpha: Portfolio is performing in line with the benchmark.",
        "feedback_alpha_negative": "Negative Alpha: Portfolio is underperforming the benchmark.",
        "feedback_hhi_high": "High Concentration: Portfolio lacks diversification.",
        "feedback_hhi_moderate": "Moderate Concentration: Portfolio has some diversification.",
        "feedback_hhi_good": "Good Diversification: Portfolio is well-diversified.",
        "success_optimize": "Portfolio optimization completed successfully!",
        "explanation_sharpe_button": "**Optimize for Highest Sharpe Ratio:**\nThe Sharpe Ratio measures the performance of your portfolio compared to a risk-free asset, after adjusting for its risk. Optimizing for the highest Sharpe Ratio aims to achieve the best possible return for the level of risk you are willing to take. This helps in constructing a portfolio that maximizes returns while minimizing unnecessary risk.",
        "recommendation": "Based on the above metrics, the **{better_portfolio}** portfolio is recommended for better **{better_metric}**."
    },
    'ja': {
        "title": "é«˜åº¦ãªæ©Ÿèƒ½ã‚’å‚™ãˆãŸãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã‚¢ãƒ—ãƒª",
        "user_inputs": "ğŸ”§ ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›",
        "select_universe": "è³‡ç”£ãƒ¦ãƒ‹ãƒãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
        "custom_tickers": "æ ªå¼ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’ã‚«ãƒ³ãƒã§åŒºåˆ‡ã£ã¦å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šAAPL, MSFT, TSLAï¼‰ï¼š",
        "add_portfolio": "ãƒã‚¤ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«è¿½åŠ ",
        "my_portfolio": "ğŸ“ ãƒã‚¤ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª",
        "no_assets": "ã¾ã è³‡ç”£ãŒè¿½åŠ ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "optimization_parameters": "ğŸ“… æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
        "start_date": "é–‹å§‹æ—¥",
        "end_date": "çµ‚äº†æ—¥",
        "risk_free_rate": "ç„¡ãƒªã‚¹ã‚¯é‡‘åˆ©ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ%ï¼‰ï¼š",
        "investment_strategy": "æŠ•è³‡æˆ¦ç•¥ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼š",
        "strategy_risk_free": "ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼æŠ•è³‡",
        "strategy_profit": "åˆ©ç›Šé‡è¦–æŠ•è³‡",
        "target_return": "ç‰¹å®šã®ç›®æ¨™ãƒªã‚¿ãƒ¼ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆ%ï¼‰",
        "train_lstm": "å°†æ¥ã®ãƒªã‚¿ãƒ¼ãƒ³äºˆæ¸¬ã®ãŸã‚ã«LSTMãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´",
        "more_info_lstm": "â„¹ï¸ LSTMã«é–¢ã™ã‚‹è©³ç´°æƒ…å ±",
        "optimize_portfolio": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’æœ€é©åŒ–",
        "optimize_sharpe": "ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§åŒ–ã®ãŸã‚ã«æœ€é©åŒ–",
        "compare_portfolios": "ã‚·ãƒ£ãƒ¼ãƒ— vs ãƒ™ãƒ¼ã‚¹ã‚’æ¯”è¼ƒ",
        "portfolio_analysis": "ğŸ” ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æã¨æœ€é©åŒ–çµæœ",
        "success_lstm": "ğŸ¤– LSTMãƒ¢ãƒ‡ãƒ«ãŒæ­£å¸¸ã«è¨“ç·´ã•ã‚Œã¾ã—ãŸï¼",
        "error_no_assets_lstm": "LSTMãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹å‰ã«ã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«å°‘ãªãã¨ã‚‚1ã¤ã®è³‡ç”£ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚",
        "error_no_assets_opt": "æœ€é©åŒ–ã™ã‚‹å‰ã«ã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«å°‘ãªãã¨ã‚‚1ã¤ã®è³‡ç”£ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚",
        "error_date": "é–‹å§‹æ—¥ã¯çµ‚äº†æ—¥ã‚ˆã‚Šå‰ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚",
        "allocation_title": "ğŸ”‘ æœ€é©ãªãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªé…åˆ†ï¼ˆç›®æ¨™ãƒªã‚¿ãƒ¼ãƒ³ï¼š{target}%)",
        "performance_metrics": "ğŸ“Š ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™",
        "visual_analysis": "ğŸ“Š è¦–è¦šçš„åˆ†æ",
        "portfolio_composition": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæ§‹æˆ",
        "portfolio_metrics": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™",
        "correlation_heatmap": "è³‡ç”£ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—",
        "var": "ãƒªã‚¹ã‚¯ä¾¡å€¤ (VaR)",
        "cvar": "æ¡ä»¶ä»˜ããƒªã‚¹ã‚¯ä¾¡å€¤ (CVaR)",
        "max_drawdown": "æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³",
        "hhi": "ãƒãƒ¼ãƒ•ã‚£ãƒ³ãƒ€ãƒ¼ãƒ«ãƒ»ãƒãƒ¼ã‚·ãƒ¥ãƒãƒ³æŒ‡æ•° (HHI)",
        "sharpe_ratio": "ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª",
        "sortino_ratio": "ã‚½ãƒ«ãƒ†ã‚£ãƒ¼ãƒãƒ¬ã‚·ã‚ª",
        "calmar_ratio": "ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ª",
        "beta": "ãƒ™ãƒ¼ã‚¿",
        "alpha": "ã‚¢ãƒ«ãƒ•ã‚¡",
        "explanation_var": "**ãƒªã‚¹ã‚¯ä¾¡å€¤ (VaR):** æŒ‡å®šã•ã‚ŒãŸä¿¡é ¼æ°´æº–ã§ã€ç‰¹å®šã®æœŸé–“å†…ã«ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãŒè¢«ã‚‹æœ€å¤§æå¤±ã‚’æ¨å®šã—ã¾ã™ã€‚",
        "explanation_cvar": "**æ¡ä»¶ä»˜ããƒªã‚¹ã‚¯ä¾¡å€¤ (CVaR):** VaRã‚’è¶…ãˆã‚‹æå¤±ã®æœŸå¾…å€¤ã‚’æ¸¬å®šã—ã€ãƒ†ãƒ¼ãƒ«ãƒªã‚¹ã‚¯ã«é–¢ã™ã‚‹æ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚",
        "explanation_max_drawdown": "**æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³:** ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ä¾¡å€¤ãŒãƒ”ãƒ¼ã‚¯ã‹ã‚‰è°·ã«ä¸‹è½ã™ã‚‹æœ€å¤§å¹…ã‚’æ¸¬å®šã—ã€æœ€æ‚ªã®ã‚·ãƒŠãƒªã‚ªã‚’ç¤ºã—ã¾ã™ã€‚",
        "explanation_hhi": "**ãƒãƒ¼ãƒ•ã‚£ãƒ³ãƒ€ãƒ¼ãƒ«ãƒ»ãƒãƒ¼ã‚·ãƒ¥ãƒãƒ³æŒ‡æ•° (HHI):** ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå†…ã®æŠ•è³‡é›†ä¸­åº¦ã‚’æ¸¬å®šã™ã‚‹å¤šæ§˜åŒ–æŒ‡æ¨™ã§ã™ã€‚",
        "explanation_sharpe_ratio": "**ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª:** ãƒªã‚¹ã‚¯èª¿æ•´å¾Œã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’æ¸¬å®šã—ã€è¿½åŠ ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«å¯¾ã—ã¦ã©ã‚Œã ã‘ã®è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’å—ã‘å–ã£ã¦ã„ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚",
        "explanation_sortino_ratio": "**ã‚½ãƒ«ãƒ†ã‚£ãƒ¼ãƒãƒ¬ã‚·ã‚ª:** ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã¨ä¼¼ã¦ã„ã¾ã™ãŒã€ä¸‹æ–¹ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®ã¿ã‚’è€ƒæ…®ã—ã€ã‚ˆã‚Šã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’çµã£ãŸãƒªã‚¹ã‚¯èª¿æ•´å¾Œã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’æä¾›ã—ã¾ã™ã€‚",
        "explanation_calmar_ratio": "**ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ª:** ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®å¹´ç‡ãƒªã‚¿ãƒ¼ãƒ³ã‚’æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã¨æ¯”è¼ƒã—ã€ãƒªã‚¹ã‚¯å˜ä½ã‚ãŸã‚Šã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã—ã¾ã™ã€‚",
        "explanation_beta": "**ãƒ™ãƒ¼ã‚¿:** ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æŒ‡æ•°ï¼ˆä¾‹ï¼šS&P 500ï¼‰ã«å¯¾ã™ã‚‹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’æ¸¬å®šã—ã¾ã™ã€‚ãƒ™ãƒ¼ã‚¿ãŒ1ã‚’è¶…ãˆã‚‹ã¨ã€ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚ˆã‚Šã‚‚é«˜ã„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ç¤ºã—ã¾ã™ã€‚",
        "explanation_alpha": "**ã‚¢ãƒ«ãƒ•ã‚¡:** ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ™ãƒ¼ã‚¿ã«åŸºã¥ãæœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³ã«å¯¾ã™ã‚‹è¶…éãƒªã‚¿ãƒ¼ãƒ³ã‚’è¡¨ã—ã¾ã™ã€‚ãƒ—ãƒ©ã‚¹ã®ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã‚¢ã‚¦ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒ ã‚’ç¤ºã—ã¾ã™ã€‚",
        "explanation_lstm": "**LSTMãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜ï¼š**\né•·çŸ­æœŸè¨˜æ†¶ï¼ˆLSTMï¼‰ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã§ä½¿ç”¨ã•ã‚Œã‚‹äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸€ç¨®ã§ã™ã€‚ç‰¹ã«æ ªå¼ãƒªã‚¿ãƒ¼ãƒ³ã®ã‚ˆã†ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚„æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬ã«åŠ¹æœçš„ã§ã™ã€‚LSTMãƒ¢ãƒ‡ãƒ«ã¯é•·æœŸé–“ã«ã‚ãŸã‚‹æƒ…å ±ã‚’ä¿æŒã§ãã‚‹ãŸã‚ã€éå»ã®é‡‘èãƒ‡ãƒ¼ã‚¿ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹ã®ã«é©ã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€LSTMã¯éå»ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ã„ã¦äºˆæ¸¬ã‚’è¡Œã†ãŸã‚ã€å¸‚å ´ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«ã‚ˆã£ã¦äºˆæ¸¬ãŒä¸ç¢ºå®Ÿã«ãªã‚‹ã“ã¨ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚ã—ãŸãŒã£ã¦ã€LSTMã®äºˆæ¸¬ã¯ä»–ã®åˆ†ææ‰‹æ³•ã¨çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚",
        "feedback_sharpe_good": "ç´ æ™´ã‚‰ã—ã„ã§ã™ï¼ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªãŒ1ä»¥ä¸Šã§ã‚ã‚Œã°ã€ãƒªã‚¹ã‚¯ã«å¯¾ã—ã¦è‰¯å¥½ãªãƒªã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚",
        "feedback_sharpe_average": "å¹³å‡çš„ã§ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªãŒ0.5ã€œ1ã®é–“ã§ã‚ã‚Œã°ã€ãƒªã‚¹ã‚¯ã«å¯¾ã—ã¦è¨±å®¹ç¯„å›²å†…ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚",
        "feedback_sharpe_poor": "ä½ã„ã§ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªãŒ0.5æœªæº€ã§ã‚ã‚Œã°ã€ãƒªã‚¹ã‚¯ã«å¯¾ã—ã¦ååˆ†ãªãƒªã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚è³‡ç”£ã®å¤šæ§˜åŒ–ã‚„æŠ•è³‡æˆ¦ç•¥ã®èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
        "feedback_sortino_good": "å„ªã‚ŒãŸã‚½ãƒ«ãƒ†ã‚£ãƒ¼ãƒãƒ¬ã‚·ã‚ªï¼ä¸‹æ–¹ãƒªã‚¹ã‚¯ã«å¯¾ã—ã¦é«˜ã„ãƒªã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ã€‚",
        "feedback_sortino_average": "å¹³å‡çš„ãªã‚½ãƒ«ãƒ†ã‚£ãƒ¼ãƒãƒ¬ã‚·ã‚ªã€‚ä¸‹æ–¹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’è€ƒæ…®ã—ãŸå ´åˆã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒªã‚¿ãƒ¼ãƒ³ã¯è¨±å®¹ç¯„å›²å†…ã§ã™ã€‚",
        "feedback_sortino_poor": "ä½ã„ã‚½ãƒ«ãƒ†ã‚£ãƒ¼ãƒãƒ¬ã‚·ã‚ªã€‚ä¸‹æ–¹ãƒªã‚¹ã‚¯ç®¡ç†ã®æ”¹å–„ã‚„ãƒªã‚¿ãƒ¼ãƒ³ã®å‘ä¸Šã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
        "feedback_calmar_good": "å„ªã‚ŒãŸã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ªï¼ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ãƒªã‚¹ã‚¯å˜ä½ã‚ãŸã‚Šã®é«˜ã„ãƒªã‚¿ãƒ¼ãƒ³ã€‚",
        "feedback_calmar_average": "è‰¯å¥½ãªã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ªã€‚ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ãƒªã‚¹ã‚¯ã«å¯¾ã—ã¦å …å®Ÿãªãƒªã‚¿ãƒ¼ãƒ³ã€‚",
        "feedback_calmar_poor": "ä½ã„ã‚«ãƒ«ãƒãƒ¼ãƒ¬ã‚·ã‚ªã€‚ãƒªã‚¿ãƒ¼ãƒ³ã®æ”¹å–„ã‚„ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³ã®å‰Šæ¸›ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚",
        "feedback_beta_high": "é«˜ãƒ™ãƒ¼ã‚¿ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚ˆã‚Šã‚‚è‘—ã—ãé«˜ã„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚",
        "feedback_beta_moderate": "ä¸­ãƒ™ãƒ¼ã‚¿ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨æ¯”è¼ƒå¯èƒ½ã§ã™ã€‚",
        "feedback_beta_low": "ä½ãƒ™ãƒ¼ã‚¿ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚ˆã‚Šã‚‚ä½ã„ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚",
        "feedback_alpha_positive": "ãƒ—ãƒ©ã‚¹ã®ã‚¢ãƒ«ãƒ•ã‚¡ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä¸Šå›ã£ã¦ã„ã¾ã™ã€‚",
        "feedback_alpha_neutral": "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨åŒç­‰ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ã™ã€‚",
        "feedback_alpha_negative": "ãƒã‚¤ãƒŠã‚¹ã®ã‚¢ãƒ«ãƒ•ã‚¡ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ä¸‹å›ã£ã¦ã„ã¾ã™ã€‚",
        "feedback_hhi_high": "é«˜é›†ä¸­åº¦ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¯å¤šæ§˜åŒ–ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚",
        "feedback_hhi_moderate": "ä¸­é›†ä¸­åº¦ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¯ã‚ã‚‹ç¨‹åº¦ã®å¤šæ§˜åŒ–ãŒã‚ã‚Šã¾ã™ã€‚",
        "feedback_hhi_good": "è‰¯å¥½ãªå¤šæ§˜åŒ–ï¼šãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¯ååˆ†ã«å¤šæ§˜åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚",
        "success_optimize": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®æœ€é©åŒ–ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼",
        "explanation_sharpe_button": "**ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§åŒ–ã®ãŸã‚ã«æœ€é©åŒ–ï¼š**\nã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã¯ã€ãƒªã‚¹ã‚¯ãƒ•ãƒªãƒ¼è³‡ç”£ã¨æ¯”è¼ƒã—ã¦ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ¸¬å®šã—ã€ãƒªã‚¹ã‚¯ã‚’èª¿æ•´ã—ãŸãƒªã‚¿ãƒ¼ãƒ³ã‚’è©•ä¾¡ã—ã¾ã™ã€‚ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªã‚’æœ€å¤§åŒ–ã™ã‚‹ã“ã¨ã§ã€ãƒªã‚¹ã‚¯ã«è¦‹åˆã£ãŸæœ€é«˜ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’é”æˆã™ã‚‹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’æ§‹ç¯‰ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒªã‚¹ã‚¯ã‚’æœ€å°é™ã«æŠ‘ãˆã¤ã¤ã€ãƒªã‚¿ãƒ¼ãƒ³ã‚’æœ€å¤§åŒ–ã™ã‚‹ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæŠ•è³‡æˆ¦ç•¥ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚",
        "recommendation": "ä¸Šè¨˜ã®æŒ‡æ¨™ã«åŸºã¥ãã€**{better_portfolio}**ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¯ã‚ˆã‚Šè‰¯ã„**{better_metric}**ã‚’æä¾›ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
    }
}

# Portfolio Optimizer Class
class PortfolioOptimizer:
    def __init__(self, tickers, start_date, end_date, risk_free_rate=0.02):
        """
        Initialize the PortfolioOptimizer with user-specified parameters.
        """
        self.tickers = tickers
        self.start_date = start_date
        self.end_date = end_date
        self.risk_free_rate = risk_free_rate
        self.returns = None

    def fetch_data(self):
        """
        Fetch historical price data and calculate daily returns.
        """
        logger.info(f"Fetching data for tickers: {self.tickers}")
        data = yf.download(
            self.tickers, start=self.start_date, end=self.end_date, progress=False
        )["Adj Close"]

        missing_tickers = set(self.tickers) - set(data.columns)
        if missing_tickers:
            st.warning(f"The following tickers were not fetched: {', '.join(missing_tickers)}")
            logger.warning(f"Missing tickers: {missing_tickers}")

        data.dropna(axis=1, inplace=True)

        if data.empty:
            logger.error("No data fetched after dropping missing tickers.")
            raise ValueError("No data fetched. Please check the tickers and date range.")

        # Update tickers to match the columns in the fetched data
        self.tickers = list(data.columns)
        self.returns = data.pct_change().dropna()
        logger.info(f"Fetched returns for {len(self.tickers)} tickers.")
        return self.tickers

    def portfolio_stats(self, weights):
        """
        Calculate portfolio return, volatility, and Sharpe ratio.
        Ensure weights align with current tickers.
        """
        weights = np.array(weights)
        if len(weights) != len(self.tickers):
            raise ValueError("Weights array length does not match the number of tickers.")
        
        # Ensure weights sum to 1
        weights = weights / np.sum(weights)
        
        portfolio_return = np.dot(weights, self.returns.mean()) * 252
        portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(self.returns.cov() * 252, weights)))
        sharpe_ratio = (portfolio_return - self.risk_free_rate) / portfolio_volatility
        return portfolio_return, portfolio_volatility, sharpe_ratio

    def value_at_risk(self, weights, confidence_level=0.95):
        """
        Calculate Value at Risk (VaR) for the portfolio.
        """
        portfolio_returns = self.returns.dot(weights)
        var = np.percentile(portfolio_returns, (1 - confidence_level) * 100)
        return var

    def conditional_value_at_risk(self, weights, confidence_level=0.95):
        """
        Calculate Conditional Value at Risk (CVaR) for the portfolio.
        """
        portfolio_returns = self.returns.dot(weights)
        var = self.value_at_risk(weights, confidence_level)
        cvar = portfolio_returns[portfolio_returns <= var].mean()
        return cvar

    def maximum_drawdown(self, weights):
        """
        Calculate Maximum Drawdown for the portfolio.
        """
        portfolio_returns = self.returns.dot(weights)
        cumulative_returns = (1 + portfolio_returns).cumprod()
        peak = cumulative_returns.cummax()
        drawdown = (cumulative_returns - peak) / peak
        max_drawdown = drawdown.min()
        return max_drawdown

    def herfindahl_hirschman_index(self, weights):
        """
        Calculate Herfindahl-Hirschman Index (HHI) for the portfolio.
        """
        return np.sum(weights ** 2)

    def sharpe_ratio_objective(self, weights):
        """
        Objective function to maximize Sharpe Ratio.
        """
        _, _, sharpe = self.portfolio_stats(weights)
        return -sharpe  # Negative because we minimize

    def optimize_sharpe_ratio(self):
        """
        Optimize portfolio to maximize Sharpe Ratio.
        """
        num_assets = len(self.tickers)
        initial_weights = np.ones(num_assets) / num_assets
        bounds = tuple((0, 1) for _ in range(num_assets))
        constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}

        result = minimize(
            self.sharpe_ratio_objective, initial_weights,
            method='SLSQP', bounds=bounds, constraints=constraints
        )

        if result.success:
            logger.info("Optimized portfolio for Sharpe Ratio successfully.")
            return result.x
        else:
            logger.warning(f"Optimization failed: {result.message}")
            return initial_weights  # Fallback to equal weights

    def min_volatility(self, target_return, max_weight=0.3):
        """
        Optimize portfolio with added weight constraints for minimum volatility.
        """
        num_assets = len(self.tickers)
        constraints = (
            {'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1},
            {'type': 'eq', 'fun': lambda weights: self.portfolio_stats(weights)[0] - target_return}
        )
        bounds = tuple((0, max_weight) for _ in range(num_assets))
        init_guess = [1. / num_assets] * num_assets

        result = minimize(
            lambda weights: self.portfolio_stats(weights)[1],
            init_guess,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints
        )

        if result.success:
            logger.info("Optimized portfolio for minimum volatility successfully.")
            return result.x
        else:
            # Log the optimization failure
            logger.warning(f"Portfolio optimization failed: {result.message}")
            # Return an equal weight portfolio as a fallback
            return np.ones(num_assets) / num_assets

    def prepare_data_for_lstm(self):
        """
        Prepare data for LSTM model.
        """
        scaler = MinMaxScaler(feature_range=(0, 1))
        scaled_data = scaler.fit_transform(self.returns.values)
        
        X, y = [], []
        look_back = 60  # Look-back period (e.g., 60 days)
        for i in range(look_back, len(scaled_data)):
            X.append(scaled_data[i-look_back:i])
            y.append(scaled_data[i])
        
        # Split into training and testing sets (e.g., 80% train, 20% test)
        split = int(len(X) * 0.8)
        X_train, X_test = X[:split], X[split:]
        y_train, y_test = y[:split], y[split:]

        if not X_train or not y_train:
            raise ValueError("Not enough data to create training samples. Please adjust the date range or add more data.")

        X_train, y_train = np.array(X_train), np.array(y_train)
        X_test, y_test = np.array(X_test), np.array(y_test)
        return X_train, y_train, X_test, y_test, scaler

    def train_lstm_model(self, X_train, y_train, epochs=10, batch_size=32):
        # Set random seed for reproducibility
        seed_value = 42
        np.random.seed(seed_value)
        tf.random.set_seed(seed_value)
        random.seed(seed_value)
        """
        Train LSTM model.
        """
        model = tf.keras.Sequential()
        model.add(tf.keras.layers.LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
        model.add(tf.keras.layers.LSTM(units=50))
        model.add(tf.keras.layers.Dense(units=X_train.shape[2]))
        model.compile(optimizer='adam', loss='mean_squared_error')
        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)
        return model

    def predict_future_returns(self, model, scaler, steps=30):
        """
        Predict future returns using the LSTM model.
        """
        if len(self.returns) < 60:
            raise ValueError("Not enough data to make predictions. Ensure there are at least 60 days of returns data.")

        last_data = self.returns[-60:].values
        scaled_last_data = scaler.transform(last_data)

        X_test = []
        X_test.append(scaled_last_data)
        X_test = np.array(X_test)
        
        predicted_scaled = model.predict(X_test)
        predicted = scaler.inverse_transform(predicted_scaled)
        
        # Ensure the length matches the number of future steps requested
        future_returns = predicted[0][:steps] if len(predicted[0]) >= steps else predicted[0]
        return future_returns

    def evaluate_model(self, model, scaler, X_test, y_test):
        """
        Evaluate the LSTM model using MAE, RMSE, and R-squared metrics.
        """
        predictions_scaled = model.predict(X_test)
        predictions = scaler.inverse_transform(predictions_scaled)
        y_test_inverse = scaler.inverse_transform(y_test)

        # Calculate evaluation metrics
        mae = mean_absolute_error(y_test_inverse, predictions)
        rmse = np.sqrt(mean_squared_error(y_test_inverse, predictions))
        r2 = r2_score(y_test_inverse, predictions)

        return mae, rmse, r2

    def compute_efficient_frontier(self, num_portfolios=10000):
        """
        Compute the Efficient Frontier by generating random portfolios.
        """
        results = np.zeros((4, num_portfolios))
        weights_record = []
        for i in range(num_portfolios):
            weights = np.random.dirichlet(np.ones(len(self.tickers)), size=1)[0]
            weights_record.append(weights)
            portfolio_return, portfolio_volatility, sharpe = self.portfolio_stats(weights)
            var = self.value_at_risk(weights, confidence_level=0.95)
            cvar = self.conditional_value_at_risk(weights, confidence_level=0.95)
            max_dd = self.maximum_drawdown(weights)
            hhi = self.herfindahl_hirschman_index(weights)
            results[0,i] = portfolio_volatility
            results[1,i] = portfolio_return
            results[2,i] = sharpe
            results[3,i] = hhi
        return results, weights_record

# Helper Functions
def extract_ticker(asset_string):
    """
    Extract ticker symbol from asset string.
    """
    return asset_string.split(' - ')[0].strip() if ' - ' in asset_string else asset_string.strip()

def get_translated_text(lang, key):
    """
    Retrieve translated text based on selected language.
    """
    return translations.get(lang, translations['en']).get(key, key)

def analyze_var(var):
    """
    Analyze Value at Risk (VaR).
    """
    if var < -0.05:
        return "High Risk: Your portfolio has a significant potential loss."
    elif -0.05 <= var < -0.02:
        return "Moderate Risk: Your portfolio has a moderate potential loss."
    else:
        return "Low Risk: Your portfolio is relatively safe."

def analyze_cvar(cvar):
    """
    Analyze Conditional Value at Risk (CVaR).
    """
    if cvar < -0.07:
        return "High Tail Risk: Significant losses beyond VaR."
    elif -0.07 <= cvar < -0.04:
        return "Moderate Tail Risk: Moderate losses beyond VaR."
    else:
        return "Low Tail Risk: Minimal losses beyond VaR."

def analyze_max_drawdown(dd):
    """
    Analyze Maximum Drawdown.
    """
    if dd < -0.20:
        return "Severe Drawdown: The portfolio has experienced a major decline."
    elif -0.20 <= dd < -0.10:
        return "Moderate Drawdown: The portfolio has experienced a noticeable decline."
    else:
        return "Minor Drawdown: The portfolio has maintained stability."

def analyze_hhi(hhi):
    """
    Analyze Herfindahl-Hirschman Index (HHI).
    """
    if hhi > 0.6:
        return "High Concentration: Portfolio lacks diversification."
    elif 0.3 < hhi <= 0.6:
        return "Moderate Concentration: Portfolio has some diversification."
    else:
        return "Good Diversification: Portfolio is well-diversified."

def analyze_sharpe(sharpe):
    """
    Analyze Sharpe Ratio.
    """
    if sharpe > 1:
        return "Great! A Sharpe Ratio above 1 indicates that your portfolio is generating good returns for the level of risk taken."
    elif 0.5 < sharpe <= 1:
        return "Average. A Sharpe Ratio between 0.5 and 1 suggests that your portfolio returns are acceptable for the risk taken."
    else:
        return "Poor. A Sharpe Ratio below 0.5 indicates that your portfolio may not be generating adequate returns for the level of risk taken. Consider diversifying your assets or adjusting your investment strategy."

def display_metrics_table(metrics, lang):
    """
    Display metrics in a structured table.
    """
    metric_display = []
    for key, value in metrics.items():
        display_key = get_translated_text(lang, key)
        if key in ["hhi"]:
            display_value = f"{value:.4f}"
        elif key in ["beta", "alpha"]:
            display_value = f"{value:.2f}"
        elif key in ["sharpe_ratio", "sortino_ratio", "calmar_ratio"]:
            display_value = f"{value:.2f}"
        else:
            display_value = f"{value:.2%}"
        
        # Get analysis
        analysis_func = {
            "var": analyze_var,
            "cvar": analyze_cvar,
            "max_drawdown": analyze_max_drawdown,
            "hhi": analyze_hhi,
            "sharpe_ratio": analyze_sharpe,
            "sortino_ratio": analyze_sharpe,  # Assuming similar feedback
            "calmar_ratio": analyze_sharpe,   # Assuming similar feedback
            "beta": analyze_sharpe,           # Assuming similar feedback
            "alpha": analyze_sharpe            # Assuming similar feedback
        }.get(key, lambda x: "")
        
        analysis = analysis_func(value)
        metric_display.append({
            "Metric": display_key,
            "Value": display_value,
            "Analysis": analysis
        })
    
    metrics_df = pd.DataFrame.from_dict(metric_display)
    st.table(metrics_df.style.set_properties(**{
        'text-align': 'left',
        'padding': '5px'
    }))

def compare_portfolios(base_metrics, optimized_metrics, lang):
    """
    Compare base and optimized portfolios and display the comparison table.
    Highlight better values in green.
    Provide a recommendation based on the comparison.
    """
    comparison_data = []
    better_portfolio = ""
    better_metric = ""

    for key in base_metrics.keys():
        base_value = base_metrics[key]
        optimized_value = optimized_metrics[key]
        metric_display = get_translated_text(lang, key)
        
        # Determine which portfolio has a better value based on the metric type
        # Higher is better for ratios and returns; lower is better for risk metrics
        if key in ["sharpe_ratio", "sortino_ratio", "calmar_ratio", "alpha"]:
            if optimized_value > base_value:
                better = "Optimized"
                better_portfolio = "Optimized"
                better_metric = metric_display
            else:
                better = "Base"
                better_portfolio = "Base"
                better_metric = metric_display
        elif key in ["var", "cvar", "max_drawdown", "beta", "hhi"]:
            if optimized_value < base_value:
                better = "Optimized"
                better_portfolio = "Optimized"
                better_metric = metric_display
            else:
                better = "Base"
                better_portfolio = "Base"
                better_metric = metric_display
        else:
            better = "-"
        
        comparison_data.append({
            "Metric": metric_display,
            "Base Portfolio": f"{base_value:.2%}" if "return" in key or key in ["sharpe_ratio", "sortino_ratio", "calmar_ratio", "alpha"] else f"{base_value:.4f}",
            "Optimized Portfolio": f"{optimized_value:.2%}" if "return" in key or key in ["sharpe_ratio", "sortino_ratio", "calmar_ratio", "alpha"] else f"{optimized_value:.4f}",
            "Better": better
        })

    comparison_df = pd.DataFrame(comparison_data)

    # Highlight better values in green
    def highlight_better(row):
        if row['Better'] == "Optimized":
            return ['background-color: lightgreen']*4
        elif row['Better'] == "Base":
            return ['background-color: lightgreen']*4
        else:
            return ['']*4

    comparison_df = comparison_df.style.apply(highlight_better, axis=1)

    st.markdown("<h3>ğŸ“Š Comparison: Sharpe vs Base Portfolio</h3>", unsafe_allow_html=True)
    st.table(comparison_df)

    # Recommendation
    if better_metric:
        recommendation_text = translations[lang].get("recommendation", "").format(better_portfolio=better_portfolio, better_metric=better_metric)
        st.markdown(f"<p><strong>Recommendation:</strong> {recommendation_text}</p>", unsafe_allow_html=True)

# Streamlit App
def main():
    # Language Selection
    st.sidebar.header("ğŸŒ Language Selection")
    selected_language = st.sidebar.selectbox("Select Language:", options=list(languages.keys()), index=0)
    lang = languages[selected_language]

    # Title
    st.title(get_translated_text(lang, "title"))

    # Sidebar for User Inputs
    st.sidebar.header(get_translated_text(lang, "user_inputs"))

    # Define preset universes
    universe_options = {
        'Tech Giants': ['AAPL - Apple', 'MSFT - Microsoft', 'GOOGL - Alphabet', 'AMZN - Amazon', 'META - Meta Platforms', 'TSLA - Tesla', 'NVDA - NVIDIA', 'ADBE - Adobe', 'INTC - Intel', 'CSCO - Cisco'],
        'Finance Leaders': ['JPM - JPMorgan Chase', 'BAC - Bank of America', 'WFC - Wells Fargo', 'C - Citigroup', 'GS - Goldman Sachs', 'MS - Morgan Stanley', 'AXP - American Express', 'BLK - BlackRock', 'SCHW - Charles Schwab', 'USB - U.S. Bancorp'],
        'Healthcare Majors': ['JNJ - Johnson & Johnson', 'PFE - Pfizer', 'UNH - UnitedHealth', 'MRK - Merck', 'ABBV - AbbVie', 'ABT - Abbott', 'TMO - Thermo Fisher Scientific', 'MDT - Medtronic', 'DHR - Danaher', 'BMY - Bristol-Myers Squibb'],
        'Custom': []
    }

    universe_choice = st.sidebar.selectbox(get_translated_text(lang, "select_universe"), options=list(universe_options.keys()), index=0)

    if universe_choice == 'Custom':
        custom_tickers = st.sidebar.text_input(
            get_translated_text(lang, "custom_tickers"),
            value=""
        )
    else:
        selected_universe_assets = st.sidebar.multiselect(
            get_translated_text(lang, "add_portfolio"),
            universe_options[universe_choice],
            default=[]  # No default selection to prevent auto-adding
        )

    # Initialize Session State for Portfolio
    if 'my_portfolio' not in st.session_state:
        st.session_state['my_portfolio'] = []

    # Initialize Session State for Portfolios' Metrics
    if 'base_portfolio_metrics' not in st.session_state:
        st.session_state['base_portfolio_metrics'] = None
    if 'optimized_portfolio_metrics' not in st.session_state:
        st.session_state['optimized_portfolio_metrics'] = None

    # Add Selected Universe Assets to Portfolio
    if universe_choice != 'Custom':
        if selected_universe_assets:
            if st.sidebar.button(get_translated_text(lang, "add_portfolio")):
                new_tickers = [extract_ticker(asset) for asset in selected_universe_assets]
                # Add only unique tickers
                st.session_state['my_portfolio'] = list(set(st.session_state['my_portfolio'] + new_tickers))
                st.sidebar.success(get_translated_text(lang, "add_portfolio") + " " + get_translated_text(lang, "my_portfolio"))
    else:
        # Add Custom Tickers to Portfolio
        if custom_tickers:
            if st.sidebar.button(get_translated_text(lang, "add_portfolio")):
                new_tickers = [ticker.strip().upper() for ticker in custom_tickers.split(",") if ticker.strip()]
                # Add only unique tickers
                st.session_state['my_portfolio'] = list(set(st.session_state['my_portfolio'] + new_tickers))
                st.sidebar.success(get_translated_text(lang, "add_portfolio") + " " + get_translated_text(lang, "my_portfolio"))

    # Display 'My Portfolio' in Sidebar
    st.sidebar.subheader(get_translated_text(lang, "my_portfolio"))
    if st.session_state['my_portfolio']:
        st.sidebar.write(", ".join(st.session_state['my_portfolio']))
    else:
        st.sidebar.write(get_translated_text(lang, "no_assets"))

    # Portfolio Optimization Parameters in Sidebar
    st.sidebar.header(get_translated_text(lang, "optimization_parameters"))

    # Date Inputs
    start_date = st.sidebar.date_input(get_translated_text(lang, "start_date"), value=datetime(2024, 1, 1), max_value=datetime.today())
    end_date = st.sidebar.date_input(get_translated_text(lang, "end_date"), value=datetime.today(), max_value=datetime.today())

    # Risk-Free Rate Input
    risk_free_rate = st.sidebar.number_input(get_translated_text(lang, "risk_free_rate"), value=2.0, step=0.1) / 100

    # Investment Strategy Options
    investment_strategy = st.sidebar.radio(
        get_translated_text(lang, "investment_strategy"),
        (get_translated_text(lang, "strategy_risk_free"), get_translated_text(lang, "strategy_profit"))
    )

    # Display Target Return Slider only if "Risk-free Investment" is selected
    if investment_strategy == get_translated_text(lang, "strategy_risk_free"):
        specific_target_return = st.sidebar.slider(
            get_translated_text(lang, "target_return"), 
            min_value=-5.0, max_value=20.0, value=5.0, step=0.1
        ) / 100
    else:
        specific_target_return = None  # Not used in Profit-focused Investment

    # Train LSTM Button
    train_lstm = st.sidebar.button(get_translated_text(lang, "train_lstm"))

    # Optimize Portfolio Button
    optimize_portfolio = st.sidebar.button(get_translated_text(lang, "optimize_portfolio"))

    # Optimize for Highest Sharpe Ratio Button
    optimize_sharpe = st.sidebar.button(get_translated_text(lang, "optimize_sharpe"))

    # Compare Portfolios Button
    compare_portfolios_btn = st.sidebar.button(get_translated_text(lang, "compare_portfolios"))

    # Main Area for Outputs
    st.header(get_translated_text(lang, "portfolio_analysis"))

    # Train LSTM Model Section
    if train_lstm:
        if not st.session_state['my_portfolio']:
            st.error(get_translated_text(lang, "error_no_assets_lstm"))
        else:
            try:
                clean_tickers = [ticker for ticker in st.session_state['my_portfolio']]
                optimizer = PortfolioOptimizer(clean_tickers, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), risk_free_rate)
                optimizer.fetch_data()

                # Prepare data for LSTM
                X_train, y_train, X_test, y_test, scaler = optimizer.prepare_data_for_lstm()
                model = optimizer.train_lstm_model(X_train, y_train, epochs=10, batch_size=32)
                mae, rmse, r2 = optimizer.evaluate_model(model, scaler, X_test, y_test)

                st.success(get_translated_text(lang, "success_lstm"))

                # Display Evaluation Metrics in Table Form
                st.subheader("LSTM Model Evaluation Metrics")
                eval_metrics = {
                    "Mean Absolute Error (MAE)": mae,
                    "Root Mean Squared Error (RMSE)": rmse,
                    "R-squared (RÂ²)": r2
                }
                eval_df = pd.DataFrame.from_dict(eval_metrics, orient='index', columns=['Value'])
                st.table(eval_df.style.format({"Value": "{:.4f}"}))

                # Predict future returns for the next 30 days
                future_returns = optimizer.predict_future_returns(model, scaler, steps=30)
                future_dates = pd.date_range(end_date, periods=len(future_returns), freq='B').to_pydatetime().tolist()  # 'B' for business days

                # Create a DataFrame for plotting
                prediction_df = pd.DataFrame({
                    'Date': future_dates,
                    'Predicted Returns': future_returns
                })

                # Plot future predictions
                fig, ax = plt.subplots(figsize=(10, 4))
                ax.plot(prediction_df['Date'], prediction_df['Predicted Returns'], label="Predicted Returns", color='blue')
                ax.set_xlabel("Date")
                ax.set_ylabel("Predicted Returns")
                ax.set_title(get_translated_text(lang, "train_lstm"))
                ax.legend()
                plt.xticks(rotation=45)
                plt.tight_layout()
                st.pyplot(fig)

                # Add LSTM Explanation using Expander
                with st.expander(get_translated_text(lang, "more_info_lstm")):
                    explanation = get_translated_text(lang, "explanation_lstm")
                    st.markdown(explanation)

            except ValueError as ve:
                st.error(str(ve))
            except Exception as e:
                logger.exception("An error occurred during LSTM training or prediction.")
                st.error(f"{e}")

    # Optimize Portfolio Section
    if optimize_portfolio:
        if not st.session_state['my_portfolio']:
            st.error(get_translated_text(lang, "error_no_assets_opt"))
        elif start_date >= end_date:
            st.error(get_translated_text(lang, "error_date"))
        else:
            try:
                clean_tickers = [ticker for ticker in st.session_state['my_portfolio']]
                optimizer = PortfolioOptimizer(clean_tickers, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), risk_free_rate)
                # Fetch data and update tickers in case some are dropped
                updated_tickers = optimizer.fetch_data()

                if investment_strategy == get_translated_text(lang, "strategy_risk_free"):
                    # Optimize for minimum volatility
                    if specific_target_return is None:
                        st.error("Please select a target return for Risk-free Investment strategy.")
                        st.stop()
                    optimal_weights = optimizer.min_volatility(specific_target_return)
                    details = "Details: You selected a 'Risk-free Investment' strategy, aiming for minimal risk exposure while attempting to achieve the specified target return."
                else:
                    # Optimize for Sharpe Ratio
                    optimal_weights = optimizer.optimize_sharpe_ratio()
                    details = "Details: You selected a 'Profit-focused Investment' strategy, aiming for maximum potential returns with an acceptance of higher risk."

                portfolio_return, portfolio_volatility, sharpe_ratio = optimizer.portfolio_stats(optimal_weights)
                var_95 = optimizer.value_at_risk(optimal_weights, confidence_level=0.95)
                cvar_95 = optimizer.conditional_value_at_risk(optimal_weights, confidence_level=0.95)
                max_dd = optimizer.maximum_drawdown(optimal_weights)
                hhi = optimizer.herfindahl_hirschman_index(optimal_weights)

                allocation = pd.DataFrame({
                    "Asset": updated_tickers,
                    "Weight (%)": np.round(optimal_weights * 100, 2)
                })
                allocation = allocation[allocation['Weight (%)'] > 0].reset_index(drop=True)

                # Display Allocation
                target_display = round(specific_target_return*100, 2) if specific_target_return else "N/A"
                st.subheader(get_translated_text(lang, "allocation_title").format(target=target_display))
                st.dataframe(allocation.style.format({"Weight (%)": "{:.2f}"}))

                # Collect all metrics
                metrics = {
                    "var": var_95,
                    "cvar": cvar_95,
                    "max_drawdown": max_dd,
                    "hhi": hhi,
                    "sharpe_ratio": sharpe_ratio,
                    "sortino_ratio": optimizer.sharpe_ratio_objective(optimal_weights),  # Placeholder
                    "calmar_ratio": optimizer.sharpe_ratio_objective(optimal_weights),   # Placeholder
                    "beta": 0.0,  # Placeholder
                    "alpha": 0.0   # Placeholder
                }

                # Update base portfolio metrics if strategy is base
                if investment_strategy == get_translated_text(lang, "strategy_risk_free"):
                    st.session_state['base_portfolio_metrics'] = metrics
                else:
                    st.session_state['optimized_portfolio_metrics'] = metrics

                # Display Performance Metrics in Table Form
                st.subheader(get_translated_text(lang, "performance_metrics"))
                display_metrics_table(metrics, lang)

                # Display Visuals
                st.subheader(get_translated_text(lang, "visual_analysis"))
                col1, col2 = st.columns(2)

                with col1:
                    # Pie Chart for Allocation
                    fig1, ax1 = plt.subplots(figsize=(5, 4))
                    ax1.pie(allocation['Weight (%)'], labels=allocation['Asset'], autopct='%1.1f%%', startangle=90, textprops={'fontsize': 10})
                    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
                    ax1.set_title(get_translated_text(lang, "portfolio_composition"))
                    st.pyplot(fig1)

                with col2:
                    # Bar Chart for Performance Metrics
                    fig2, ax2 = plt.subplots(figsize=(5, 4))
                    performance_metrics = {
                        "Expected Annual Return (%)": portfolio_return * 100,
                        "Annual Volatility\n(Risk) (%)": portfolio_volatility * 100,
                        "Sharpe Ratio": sharpe_ratio
                    }
                    metrics_bar = pd.DataFrame.from_dict(performance_metrics, orient='index', columns=['Value'])
                    sns.barplot(x=metrics_bar.index, y='Value', data=metrics_bar, palette='viridis', ax=ax2)
                    ax2.set_title(get_translated_text(lang, "portfolio_metrics"))
                    for p in ax2.patches:
                        ax2.annotate(f"{p.get_height():.2f}", (p.get_x() + p.get_width() / 2., p.get_height()),
                                     ha='center', va='bottom', fontsize=10)
                    plt.xticks(rotation=0, ha='center')  # Adjust rotation if needed
                    plt.tight_layout()
                    st.pyplot(fig2)

                # Correlation Heatmap
                st.subheader(get_translated_text(lang, "correlation_heatmap"))
                correlation_matrix = optimizer.returns.corr()
                fig3, ax3 = plt.subplots(figsize=(8, 6))
                sns.heatmap(correlation_matrix, annot=True, cmap='Spectral', linewidths=0.3, ax=ax3, cbar_kws={'shrink': 0.8}, annot_kws={'fontsize': 8})
                plt.title(get_translated_text(lang, "correlation_heatmap"))
                plt.tight_layout()
                st.pyplot(fig3)

                st.success(get_translated_text(lang, "success_optimize"))

            except ValueError as ve:
                st.error(str(ve))
            except Exception as e:
                logger.exception("An unexpected error occurred during optimization.")
                st.error(f"{e}")

    # Optimize for Highest Sharpe Ratio Section
    if optimize_sharpe:
        if not st.session_state['my_portfolio']:
            st.error(get_translated_text(lang, "error_no_assets_opt"))
        elif start_date >= end_date:
            st.error(get_translated_text(lang, "error_date"))
        else:
            try:
                clean_tickers = [ticker for ticker in st.session_state['my_portfolio']]
                optimizer = PortfolioOptimizer(clean_tickers, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'), risk_free_rate)
                # Fetch data and update tickers in case some are dropped
                updated_tickers = optimizer.fetch_data()

                # Optimize for Highest Sharpe Ratio
                optimal_weights = optimizer.optimize_sharpe_ratio()
                portfolio_return, portfolio_volatility, sharpe_ratio = optimizer.portfolio_stats(optimal_weights)
                var_95 = optimizer.value_at_risk(optimal_weights, confidence_level=0.95)
                cvar_95 = optimizer.conditional_value_at_risk(optimal_weights, confidence_level=0.95)
                max_dd = optimizer.maximum_drawdown(optimal_weights)
                hhi = optimizer.herfindahl_hirschman_index(optimal_weights)

                allocation = pd.DataFrame({
                    "Asset": updated_tickers,
                    "Weight (%)": np.round(optimal_weights * 100, 2)
                })
                allocation = allocation[allocation['Weight (%)'] > 0].reset_index(drop=True)

                # Display Allocation
                st.subheader("ğŸ”‘ Optimal Portfolio Allocation (Highest Sharpe Ratio)")
                st.dataframe(allocation.style.format({"Weight (%)": "{:.2f}"}))

                # Collect all metrics
                metrics = {
                    "var": var_95,
                    "cvar": cvar_95,
                    "max_drawdown": max_dd,
                    "hhi": hhi,
                    "sharpe_ratio": sharpe_ratio,
                    "sortino_ratio": 0.0,  # Placeholder
                    "calmar_ratio": 0.0,    # Placeholder
                    "beta": 0.0,             # Placeholder
                    "alpha": 0.0             # Placeholder
                }

                # Update optimized portfolio metrics
                st.session_state['optimized_portfolio_metrics'] = metrics

                # Display Performance Metrics in Table Form
                st.subheader(get_translated_text(lang, "performance_metrics"))
                display_metrics_table(metrics, lang)

                # Display Visuals
                st.subheader(get_translated_text(lang, "visual_analysis"))
                col1, col2 = st.columns(2)

                with col1:
                    # Pie Chart for Allocation
                    fig1, ax1 = plt.subplots(figsize=(5, 4))
                    ax1.pie(allocation['Weight (%)'], labels=allocation['Asset'], autopct='%1.1f%%', startangle=90, textprops={'fontsize': 10})
                    ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
                    ax1.set_title(get_translated_text(lang, "portfolio_composition"))
                    st.pyplot(fig1)

                with col2:
                    # Bar Chart for Performance Metrics
                    fig2, ax2 = plt.subplots(figsize=(5, 4))
                    performance_metrics = {
                        "Expected Annual Return (%)": portfolio_return * 100,
                        "Annual Volatility\n(Risk) (%)": portfolio_volatility * 100,
                        "Sharpe Ratio": sharpe_ratio
                    }
                    metrics_bar = pd.DataFrame.from_dict(performance_metrics, orient='index', columns=['Value'])
                    sns.barplot(x=metrics_bar.index, y='Value', data=metrics_bar, palette='viridis', ax=ax2)
                    ax2.set_title(get_translated_text(lang, "portfolio_metrics"))
                    for p in ax2.patches:
                        ax2.annotate(f"{p.get_height():.2f}", (p.get_x() + p.get_width() / 2., p.get_height()),
                                     ha='center', va='bottom', fontsize=10)
                    plt.xticks(rotation=0, ha='center')  # Adjust rotation if needed
                    plt.tight_layout()
                    st.pyplot(fig2)

                # Correlation Heatmap
                st.subheader(get_translated_text(lang, "correlation_heatmap"))
                correlation_matrix = optimizer.returns.corr()
                fig3, ax3 = plt.subplots(figsize=(8, 6))
                sns.heatmap(correlation_matrix, annot=True, cmap='Spectral', linewidths=0.3, ax=ax3, cbar_kws={'shrink': 0.8}, annot_kws={'fontsize': 8})
                plt.title(get_translated_text(lang, "correlation_heatmap"))
                plt.tight_layout()
                st.pyplot(fig3)

                # Compute and Plot Efficient Frontier
                st.subheader("ğŸ“ˆ Efficient Frontier")
                results, weights_record = optimizer.compute_efficient_frontier()
                portfolio_volatility = results[0]
                portfolio_return = results[1]
                sharpe_ratios = results[2]

                # Find the portfolio with the highest Sharpe Ratio
                max_sharpe_idx = np.argmax(sharpe_ratios)
                max_sharpe_vol = portfolio_volatility[max_sharpe_idx]
                max_sharpe_ret = portfolio_return[max_sharpe_idx]

                # Plot Efficient Frontier
                fig4, ax4 = plt.subplots(figsize=(10, 6))
                scatter = ax4.scatter(portfolio_volatility, portfolio_return, c=sharpe_ratios, cmap='viridis', marker='o', s=10, alpha=0.3)
                sc = ax4.scatter(max_sharpe_vol, max_sharpe_ret, c='red', marker='*', s=200, label='Max Sharpe Ratio')
                plt.colorbar(scatter, label='Sharpe Ratio')
                ax4.scatter(max_sharpe_vol, max_sharpe_ret, c='red', marker='*', s=200, label='Max Sharpe Ratio')
                ax4.set_xlabel('Annual Volatility (Risk)')
                ax4.set_ylabel('Expected Annual Return')
                ax4.set_title('Efficient Frontier')
                ax4.legend()
                plt.tight_layout()
                st.pyplot(fig4)

                # Display Analysis for Highest Sharpe Ratio Portfolio
                st.markdown("**Analysis:** This portfolio offers the highest Sharpe Ratio, meaning it provides the best risk-adjusted return among the sampled portfolios.")

                # Display the optimized portfolio metrics again for clarity
                st.subheader("ğŸ” Detailed Metrics for Highest Sharpe Ratio Portfolio")
                detailed_metrics = {
                    "Expected Annual Return (%)": max_sharpe_ret * 100,
                    "Annual Volatility\n(Risk) (%)": max_sharpe_vol * 100,
                    "Sharpe Ratio": sharpe_ratios[max_sharpe_idx],
                    "Value at Risk (VaR)": optimizer.value_at_risk(weights_record[max_sharpe_idx], confidence_level=0.95),
                    "Conditional Value at Risk (CVaR)": optimizer.conditional_value_at_risk(weights_record[max_sharpe_idx], confidence_level=0.95),
                    "Maximum Drawdown": optimizer.maximum_drawdown(weights_record[max_sharpe_idx]),
                    "Herfindahl-Hirschman Index (HHI)": optimizer.herfindahl_hirschman_index(weights_record[max_sharpe_idx])
                }
                detailed_metrics_df = pd.DataFrame.from_dict(detailed_metrics, orient='index', columns=['Value'])
                st.table(detailed_metrics_df.style.format({"Value": lambda x: f"{x:.2f}"}))

                # Display Risk Metrics with Explanations and Feedback
                st.subheader("ğŸ“Š Detailed Performance Metrics")
                for key in ["Expected \n Annual Return (%)", "Annual Volatility\n(Risk) (%)", "Sharpe Ratio", "Value at Risk (VaR)", "Conditional Value at Risk (CVaR)", "Maximum Drawdown", "Herfindahl-Hirschman Index (HHI)"]:
                    value = detailed_metrics.get(key, None)
                    if value is not None:
                        display_value = f"{value:.2f}" if key in ["Sharpe Ratio"] else (f"{value:.2f}%" if "%" in key else f"{value:.4f}")
                        st.markdown(f"**{key}:** {display_value}")

                        # Provide feedback based on the metric
                        if key == "Value at Risk (VaR)":
                            feedback = analyze_var(value)
                        elif key == "Conditional Value at Risk (CVaR)":
                            feedback = analyze_cvar(value)
                        elif key == "Maximum Drawdown":
                            feedback = analyze_max_drawdown(value)
                        elif key == "Herfindahl-Hirschman Index (HHI)":
                            feedback = analyze_hhi(value)
                        elif key == "Sharpe Ratio":
                            feedback = analyze_sharpe(value)
                        else:
                            feedback = ""

                        if feedback:
                            st.markdown(f"**Analysis:** {feedback}")

                st.success(get_translated_text(lang, "explanation_sharpe_button"))

            except ValueError as ve:
                st.error(str(ve))
            except Exception as e:
                logger.exception("An unexpected error occurred during Sharpe Ratio optimization.")
                st.error(f"{e}")

    # Compare Portfolios Section
    if compare_portfolios_btn:
        if st.session_state['base_portfolio_metrics'] is None or st.session_state['optimized_portfolio_metrics'] is None:
            st.error("Please optimize both the base portfolio and the highest Sharpe Ratio portfolio before comparing.")
        else:
            base_metrics = st.session_state['base_portfolio_metrics']
            optimized_metrics = st.session_state['optimized_portfolio_metrics']
            compare_portfolios(base_metrics, optimized_metrics, lang)

 

if __name__ == "__main__":
    main()
